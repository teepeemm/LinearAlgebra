\chapter{\solutionSetsTitle}

Algebra problems can have multiple solutions. For example $x(x-1)=0$ has  two solutions: $0$ and $1$. By contrast, equations of the form $Ax=b$ with $A$ a linear operator have have the following property.\\



If $A$ is a linear operator and $b$ is a known then $Ax=b$ has either
\begin{enumerate}
\item One solution
\item  No solutions
\item Infinitely many solutions
\end{enumerate}


\section{The Geometry of Solution Sets: Hyperplanes}
Consider the following algebra problems and their solutions

\begin{enumerate}
\item $6x=12$, one solution: $2$
\item $0x=12$, no solution
\item $0x=0$, one solution for each number: $x$
\end{enumerate}
In each case the linear operator is a $1\times 1$ matrix. In the first case, the linear operator is invertible. 
In the other two cases it is not. 
In the first case, the solution set is a point on the number line, in the third case the solution set is the whole number line.

Lets examine similar situations with larger matrices.
\begin{enumerate}
\item
$\begin{pmatrix}
6	&0 	\\
0 	&2 	
\end{pmatrix} 
\begin{pmatrix}
 x \\ 
y 
\end{pmatrix} 
=
\begin{pmatrix}
12 \\ 
6
\end{pmatrix}$, one solution: 
$\begin{pmatrix}
2 \\ 
3
\end{pmatrix}$
%\\linear operator is invertible

\item 
$\begin{pmatrix}
1	&3 	\\
0 	&0 	
\end{pmatrix} 
\begin{pmatrix}
 x \\ 
y 
\end{pmatrix} 
=
\begin{pmatrix}
4 \\ 
1 
\end{pmatrix}$, no solutions
%not in the range of the linear operator

\item 
$\begin{pmatrix}
1	&3 	\\
0 	&0 	
\end{pmatrix} 
\begin{pmatrix}
 x \\ 
y 
\end{pmatrix} 
=
\begin{pmatrix}
4 \\ 
0
\end{pmatrix} $, one solution for each number $y$: 
$\begin{pmatrix}
4-3y \\ 
y
\end{pmatrix} $

\item 
$\begin{pmatrix}
0	&0 	\\
0 	&0 	
\end{pmatrix} 
\begin{pmatrix}
 x \\ 
y 
\end{pmatrix} 
=
\begin{pmatrix}
0 \\ 
0
\end{pmatrix} $, one solution for each pair of numbers $x,y$:
$\begin{pmatrix}
x\\ 
y
\end{pmatrix} $
\end{enumerate}
Again, in the first case the linear operator is invertible while in the other cases it is not. When the operator is not invertible the solution set can be empty, a line in the plane or the plane itself.


For a system of equations with $r$ equations and $k$ veriables, one can have a number of different outcomes.  For example, consider the case of $r$ equations in three variables.  Each of these equations is the equation of a plane in three-dimensional space.  To find solutions to the system of equations, we look for the common intersection of the planes (if an intersection exists).  Here we have five different possibilities:

\begin{enumerate}
\item \textbf{Unique Solution.}  The planes have a unique point of intersection.

\item \textbf{No solutions.}  Some of the equations are contradictory, so no solutions exist.

\item \textbf{Line.}  The planes intersect in a common line; any point on that line then gives a solution to the system of equations.

\item \textbf{Plane.}  Perhaps you only had one equation to begin with, or else all of the equations coincide geometrically.  In this case, you have a plane of solutions, with two free parameters.

\videoscriptlink{solution_sets_for_systems_of_linear_equations_planes.mp4}{Planes}{solution_sets_for_systems_of_linear_equations_planes}

\item \textbf{All of $\mathbb{R}^3$.}  If you start with no information, then any point in $\mathbb{R}^3$ is a solution.  There are three free parameters.
\end{enumerate}

In general, for systems of equations with $k$ unknowns, there are $k+2$ possible outcomes, corresponding to the possible numbers (i.e. $0,1,2,\dots,k$) of free parameters in the solutions set plus the possibility of no solutions.  These types of ``solution sets''\index{Solution set} are ``hyperplanes''\index{Hyperplane}, generalizations of planes the behave like planes in $\mathbb{R}^3$ in many ways.

\videoscriptlink{solution_sets_for_systems_of_linear_equations_overview.mp4}{Pictures and Explanation}{solution_sets_for_systems_of_linear_equations_overview}

\vspace{3mm}

\reading{4}{1}
%\begin{center}\href{\webworkurl ReadingHomework4/1/}{Reading homework: problem 4.1}\end{center}



\section{Particular Solution $+$ Homogeneous solutions }

In the \hyperlink{standard approach}{standard approach}, variables corresponding to columns that do not contain a pivot (after going to reduced row echelon form) are \emph{free}.  
We called them non-pivot variables. 
They index elements of the solutions set by acting as coefficients of vectors.
%In this way the number of non-pivot columns determines (in part) the size of the solution set.  
%We can denote them with dummy variables $\mu_1, \mu_2, \ldots$. 

\begin{example} (Non-pivot columns determine terms of the solutions)
$$\begin{pmatrix}
1 &  0 & 1 & -1 \\ 
 0 & 1 & -1& 1  \\
 0 &0   & 0  & 0 \\
\end{pmatrix}
\colvec{x_1\\x_2\\x_3\\x_4} 
=
\colvec{1\\1\\0} 
\Leftrightarrow
\left\{
\begin{array}{lcr}
	1x_1 +0x_2+ 1x_3 - 1x_4 & = 1 \\
	0x_1 +1x_2 - 1x_3 + 1x_4 & = 1 \\
	0x_1 +0x_2 + 0x_3 + 0x_4 & = 0 
\end{array}
     \right.
$$
Following the standard approach, express the pivot variables in terms of the non-pivot variables and add ``freebee equations". Here $x_3$ and $x_4$ are non-pivot variables.  
\begin{eqnarray*}
\left.
\begin{array}{rcl}
	x_1 & = &1 -x_3+x_4 \\
	x_2 & = &1 +x_3-x_4 \\
	x_3 & = &\phantom{1+~\,}x_3\\
	x_4 & =&\phantom{1+x_3+~}x_4         
\end{array}
     \right\}
     \Leftrightarrow
\colvec{x_1\\x_2\\x_3\\x_4} 
= \colvec{1\\1\\0\\0} + x_3\colvec{-1\\1\\1\\0} + x_4\colvec{1\\-1\\0\\1}
\end{eqnarray*}
The preferred way to write a solution set is with set notation\index{Solution set!set notation}.  \[S = \left\{\colvec{x_1\\x_2\\x_3\\x_4} = \colvec{1\\1\\ 0\\0 } + \mu_1 \colvec{-1\\1\\1\\0 }  + \mu_2  \colvec{1\\-1\\ 0 \\1 } : \mu_1,\mu_2\in  {\mathbb R} \right\} \]
Notice that the first two components of the second two terms come from the non-pivot columns
Another way to write the solution set is
\[S= \left\{  X_0 + \mu_1 Y_1 + \mu_2 Y_2   : \mu_1,\mu_2 \in  {\mathbb R}   \right\} \]
where 
\[X_0= \colvec{1\\1\\0 \\0 }, Y_1=\colvec{-1\\1\\1\\0 } , Y_2= \colvec{1\\-1\\0 \\1 }
\]
\end{example}
Here $X_0$ is called a particular solution while $Y_1$ and $Y_2$ are called homogeneous solutions. 



\section{Linearity and these parts}
%
%\begin{definition}   A function $f$ is \emph{linear}\index{Linear!function} if 
%for any vectors $X,Y$  in the domain of $f$, and any scalars $\alpha,\beta$ 
%\[f(\alpha X + \beta Y) = \alpha f(X) + \beta f(Y) \,.\]
%\end{definition}

%
%
%\begin{example}
%\hypertarget{solution_sets_for_systems_of_linear_equations_concrete_example}{Consider our example system above with} 
%\[
%M=    \begin{pmatrix}
%      1  & 0  & 1 & -1  \\
%       0  & 1 & -1 & 1  \\
%        0 &0   & 0  & 0    \\
%    \end{pmatrix} \, ,\quad
%X= \colvec{x_1\\x_2\\x_3\\x_4} \mbox{ and } Y=\colvec{y_1\\y_2\\y^3 \\y^4 }\, ,
%\]
%and take for the function of vectors
%$$
%f(X)=MX\, .
%$$
%Now let us check the linearity property for $f$. 
%The property needs to hold for {\it any} scalars $\alpha$ and $\beta$, so for simplicity
%let us concentrate first on the case $\alpha=\beta=1$. This means that we need to
%compare the following two calculations:
%\begin{enumerate}
%\item First add $X+Y$, then compute $f(X+Y)$.
%\item First compute $f(X)$ and $f(Y)$, then compute the sum $f(X)+f(Y)$.
%\end{enumerate}
%The second computation is slightly easier:
%$$
%f(X) = MX 
%    =\colvec{x_1+x_3-x_4\\x_2-x_3+x_4\\0}\mbox{ and }
%f(Y) = MY   
%    =\colvec{y_1+y_3-y_4\\y_2-y_3+y_4\\0}\, ,
%$$
%(using our result above). Adding these gives
%$$
%f(X)+f(Y)=\colvec{x_1+x_3-x_4+y_1+y_3-y_4\\[1mm]x_2-x_3+x_4+y_2-y_3+y_4\\[1mm]0}\, .
%$$
%Next we perform the first computation beginning with:
%$$
%X+Y=\colvec{x_1 + y_1\\x_2+y_2\\ x_3+y_3\\ x_4+y_4}\, ,
%$$
%from which we calculate
%$$
%f(X+Y)=\colvec{x_1+y_2+x_3+y_3-(x_4+y_4)\\[1mm] x_2+y_2-(x_3+y_3)+x_4+y_4\\[1mm]0}\, .
%$$
%Distributing the minus signs and remembering that the order of adding numbers like $x_1,x_2,\ldots$ 
%does not matter, we see that the two computations give exactly the same answer.
%
%Of course, you should complain that we took a special choice of $\alpha$ and $\beta$.
%Actually, to take care of this we only need to check that $f(\alpha X)=\alpha f(X)$.
%It is your job to explain this in  \hyperref[linear]{Review Question~\ref*{linear}}
%\end{example}
%
%\noindent
%Later we will show that matrix multiplication is always linear.  Then we will know that:
With the previous example in mind, lets say that the matrix equation $MX=V$ has  solution set  $\{ X_0 + \mu_1 Y_1 + \mu_2 Y_2):\mu_1,\mu_2 \in {\mathbb R} \}$.
Recall from \hyperlink{{Matrices are linear operators}}{earlier} that matrices are linear.
%\[M(\alpha X + \beta Y) = \alpha MX + \beta MY\]
%
%Then 
%
%the two equations 
Thus 
$$M( X_0 + \mu_1 Y_1 + \mu_2 Y_2)  = MX_0 + \mu_1MY_1 + \mu_2MY_2 =V$$
for \emph{any} $\mu_1, \mu_2 \in \mathbb{R}$. 
Choosing $\mu_1=\mu_2=0$, we obtain 
$$MX_0=V\, .$$  
This is why $X_0$ is an example of a  \emph{particular solution}\index{Particular solution!an example}.

%Given a particular solution to the system, we can then deduce that $\mu_1MY_1 + \mu_2MY_2 = 0$.  
Setting $\mu_1=1, \mu_2=0$, and using the particular solution $MX_0=V$, we obtain 
$$MY_1=0\, .$$ 
Likewise, setting $\mu_1=0, \mu_2=1$, we obtain $$MY_2=0\, .$$
Here $Y_1$ and $Y_2$ are examples of what are called  \emph{homogeneous} solutions\index{Homogeneous solution!an example} to the system.
They {\it do not} solve the original equation $MX=V$, but instead its associated 
{\it homogeneous  equation}\index{homogeneous equation} $M Y =0$.

One of the fundamental lessons of linear algebra: the  solution set to $Ax=b$ with $A$ a linear operator consists of a particular solution plus homogeneous solutions.

\begin{center}
\shabox{
general solution $=$ particular solution $+$ homogeneous solutions.}
\end{center}

\begin{example}
Consider the matrix equation of the previous example. It has  solution set
\[S = \left\{\colvec{x_1\\x_2\\x_3\\x_4} = \colvec{1\\1\\0 \\0 } + \mu_1 \colvec{-1\\1\\1\\0 } + \mu_2 \colvec{1\\-1\\ 0\\1 } \right\} \]
Then $MX_0=V$ says that $\colvec{x_1\\x_2\\x_3\\x_4} = 
\colvec{1\\1\\0 \\ 0}$ solves the original matrix equation, which is certainly true, but this is not the only solution.

$MY_1=0$ says that $\colvec{x_1\\x_2\\x_3\\x_4} = \colvec{-1\\1\\1\\ 0}
$ solves the homogeneous equation.

\vspace{2mm}

$MY_2=0$ says that $\colvec{x_1\\x_2\\x_3\\x_4} = 
\colvec{1\\-1\\0 \\1}$ solves the homogeneous equation.

\vspace{2mm}

\noindent
Notice how adding any multiple of a homogeneous solution to the particular solution yields another particular solution.
\end{example}

%\begin{definition}
%Let $M$ a matrix and $V$ a vector.  Given the linear system $MX=V$, we call $X_0$ a \emph{particular solution}\index{Particular solution} if $MX_0=V$.  We call $Y$ a \emph{homogeneous solution} if $MY=0$.  
%The linear system 
%$$MX=0$$ is called the (associated) \emph{homogeneous system}\index{Homogeneous system}.
%\end{definition}
%
%If $X_0$ is a particular solution, then the general solution\index{General solution} to the system is\footnote{The notation \(S=\{X_0+Y : MY=0\}\) is read, ``\(S\) is the set of all \(X_0+Y\) such that \(MY=0,\)'' and means exactly that. Sometimes a pipe \(|\) is used instead of a colon.}:
%
%\[S= \{X_0+Y : MY=0 \} \]

\reading{4}{2}
%\begin{center}\href{\webworkurl ReadingHomework4/2/}{Reading homework: problem 4.2}\end{center}

%\section*{References}
%
%Hefferon, Chapter One, Section I.2
%\\
%Beezer, Chapter SLE, Section TSS
%\\
%Wikipedia, \href{http://en.wikipedia.org/wiki/System_of_linear_equations}{Systems of Linear Equations}


%\section{The size of solution sets vs size of homogeneous solution set}


\section{Review Problems}

\input{\solutionSetsPath/problems}


\newpage
