


\begin{enumerate}
\item Let $P_n(t)$ be the vector space of polynomials of degree $n$ or less, and $\frac{d}{dt} \colon P_n(t) \to P_{n}(t)$ be the derivative operator.  Find the matrix of $\frac{d}{dt}$ in the ordered bases $E=(1,t,\ldots,t^n )$ for the domain and $F=(t^{n}, \ldots, ,t,1 )$ for the codomain. Determine if this derivative operator is diagonalizable. 

\emph{Recall from 
\hyperref[sec:linearTransformation]{Chapter~\ref*{sec:linearTransformation}}} 
that \hyperlink{derivative_linear}{the derivative operator is linear} .

\phantomnewpage

\item When writing a matrix for a linear transformation, we have seen that the choice of basis matters.  In fact, even the order of the basis matters!
\begin{enumerate}
\item Write all possible reorderings of the standard basis $(e_1,e_2,e_3)$ for~$\Re^3$.
\item Write each change of basis matrix between the standard basis and each of its reorderings.  Make as many observations as you can about these matrices. what are their entries? Do you notice anything about how many of each type of entry appears in each row and column? What are their determinants?  (Note: These matrices are known as \emph{permutation matrices}\index{Permutation matrices}.)
\item Given $L:\Re^3\to \Re^3$ is linear and  
$$
L\colvec{x\\y\\z}=\ccolvec{2y-z\\3x\\2z+x+y}
$$ 
write the matrix $M$ for $L$ in the standard basis, and two reorderings of the standard basis.  How are these matrices related?
\end{enumerate}

\phantomnewpage

\item Let $$X=\{\heartsuit,\clubsuit,\spadesuit\}\, ,\quad Y=\{*,\star\}\, .$$ Write down two different ordered bases, $S,S'$ and $T,T'$ respectively, for each of the vector spaces ${\mathbb R}^X$ and ${\mathbb R}^Y$. Find the change of basis matrices $P$ and $Q$ that map these bases to one another. Now consider the map
$$
\ell:Y\to X\, ,
$$
where $\ell(*)=\heartsuit$ and $\ell(\star)=\spadesuit$. Show that $\ell$ can be used to define a linear transformation $L:{\mathbb R}^X\to{\mathbb R}^Y$. Compute the matrices $M$ and $M'$ of $L$ in the bases $S,T$ and then $S',T'$. Use your change of basis matrices $P$ and $Q$ to 
check that $M'=Q^{-1}MP$.

\item Recall that $\tr MN = \tr NM$. Use this fact to show that the trace of a square matrix~$M$ does not depend on the basis you used to compute~$M$.



\item When is the $2\times 2$ matrix 
$\begin{pmatrix}
a & b \\
c & d \\
\end{pmatrix}$ diagonalizable?  Include examples in your answer.

\phantomnewpage

\item Show that similarity of matrices is an \hypertarget{equivalence}{\emph{equivalence relation}}\index{Equivalence relation}.  (The definition of an equivalence relation is given in the  \href{\webworkurl Background/4/}{background} WeBWorK set.)

\phantomnewpage

\item {\it Jordan form} \label{prob_jordan_form}
\begin{itemize}
\item Can the matrix \(\begin{pmatrix}
\lambda & 1 \\
0 & \lambda \\
\end{pmatrix}\) be diagonalized? Either diagonalize it or explain why this is impossible.
\item Can the matrix \(\begin{pmatrix}
\lambda & 1 & 0 \\
0 & \lambda & 1 \\
0 & 0 & \lambda \\
\end{pmatrix}\) be diagonalized? Either diagonalize it or explain why this is impossible.
\item Can the \(n \times n\) matrix \(\begin{pmatrix}
\lambda & 1 & 0 & \cdots & 0 & 0 \\
0 & \lambda & 1 & \cdots & 0 & 0 \\
0 & 0 & \lambda & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & \lambda & 1 \\
0 &  & 0 & \cdots & 0 & \lambda \\
\end{pmatrix}\) be diagonalized? Either diagonalize it or explain why this is impossible.

{\it Note:} It turns out that every matrix is similar to a block matrix whose diagonal blocks look like diagonal matrices or the ones above and whose off-diagonal blocks are all zero. This is called the {\it Jordan form} of the matrix and a (maximal) block that looks like
\[
\left(
\begin{array}{ccccc}
\lambda & 1 & 0&\cdots & 0 \\
0 & \lambda & 1 & & 0 \\
\vdots &  &\ddots &\ddots &  \\
&&&\lambda&1\\
0 &0 &&  0 & \lambda
\end{array}\right)
\]
is called a \emph{Jordan $n$-cell}\index{Jordan cell} or a \emph{Jordan block} where $n$ is the size of the block.
\end{itemize}

\phantomnewpage

\item Let $A$ and $B$ be commuting matrices ({\it i.e.}, $AB = BA$) and suppose that $A$ has an eigenvector $v$ with eigenvalue $\lambda$. 
\begin{enumerate}
\item Show that $Bv$ is also  an eigenvector of $A$ with eigenvalue $\lambda$. 
\item Additionally suppose that $A$ is diagonalizable with distinct eigenvalues. What is the dimension of each eigenspace of $A$?
\item Show that $v$ is also an eigenvector of $B$. 
\item Explain why this shows that $A$ and $B$ can be \emph{simultaneously diagonalized} ({\it i.e.}
there is an ordered basis in which  both their matrices are diagonal).
\end{enumerate}






\end{enumerate}

%\phantomnewpage