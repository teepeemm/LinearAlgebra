\chapter{Fields}

%\section{Abstract Concepts}
%
%Here we will introduce  some abstract concepts which are mentioned or used in this book. This is material is more advanced but will be interesting to anybody wanting a deeper understanding of the underlying mathematical structures behind linear algebra.  In all cases below, we assume that the given set is closed under the operation(s) introduced.
%
%\subsection{Dual Spaces}
%\label{dualspaces}
%
%\begin{definition}
%\index{Bounded operator}
%A \emph{bounded operator} is a linear operator $\phi \colon V \rightarrow W$ such that $\norm{\phi v}_W \leq C \norm{v}_V$ where $C > 0$ is a fixed constant.
%\end{definition}
%
%Let $V$ be a vector space over $\mathbb{F}$, and a \emph{functional} is a function $\phi \colon V \rightarrow \mathbb{F}$.
%
%\begin{definition}
%\index{Dual space}
%The \emph{dual space} $V^*$ of a vector space $V$ is the vector space of all bounded linear functionals on $V$.
%\end{definition}
%
%There is a natural basis $\{ \Lambda_i \}$ for $V^*$ by $\Lambda_i(e_j) = \delta_{ij}$ where $\{e_j\}$ is the canonical (standard) basis for $V$ and $\delta_{ij}$ is the \emph{Kronecker delta}\index{Kronecker delta}, which is 1 if $i = j$ and 0 otherwise. Concretely for a finite dimensional vector space $V$, we can associate $V^*$ with row vectors $w^T$ as a functional by the matrix multiplication $w^T v$ for vectors $v \in V$. Alternatively we can associated $V^*$ with vectors in $V$ as a functional by taking the usual dot product. So the basis for $V^*$ is $e_i^T$ or $\langle e_i, v \rangle$ for vectors $v \in V$.

%\subsection{Groups}
%\label{groups}
%
%\begin{definition}
%\index{Group}
%A \emph{group} is a set $G$ with a single operation $\cdot$ which satisfies the axioms:
%\begin{itemize}
%\item Associativity $(a \cdot b) \cdot c = a \cdot (b \cdot c)$ for all $a,b,c \in G$.
%
%\item There exists an identity $1 \in G$.
%
%\item There exists an inverse $g^{-1} \in G$ for all $g \in G$.
%\end{itemize}
%\end{definition}
%
%Groups can be finite or infinite, and notice that not alls element in a group must commute ({\it i.e.}, the order of multiplication can matter). Here are some examples of groups:
%\begin{itemize}
%\item Non-zero real numbers under multiplication.
%
%\item All real numbers under addition.
%
%\item All invertible $n \times n$ real matrices.
%
%\item All $n \times n$ real matrices of determinant 1.
%
%\item All permutations of $[1, 2, \dotsc, n]$ \hyperref[problem_permutation]{under compositions}.
%
%\item Any vector space under addition.
%\end{itemize}
%Note that all real numbers under multiplication is not a group since $0$ does not have an inverse.



%\subsection{Fields}
\label{fields}

\begin{definition}
\index{Field}
A \emph{field} $\mathbb{F}$ is a set with two operations $+$ and $\cdot$, such that for all $a, b, c \in \mathbb{F}$  the following axioms are satisfied:
\begin{itemize}
\item[A1.] Addition is associative $(a + b) + c = a + (b + c)$.

\item[A2.] There exists an additive identity $0$.

\item[A3.] Addition is commutative $a + b = b + a$.

\item[A4.] There exists an additive inverse $-a$.

\item[M1.] Multiplication is associative $(a \cdot b) \cdot c = a \cdot (b \cdot c)$.

\item[M2.] There exists a multiplicative identity $1$.

\item[M3.] Multiplication is commutative $a \cdot b = b \cdot a$.

\item[M4.] There exists a multiplicative inverse $a^{-1}$ if $a \neq 0$.

\item[D.] The distributive law holds $a \cdot (b + c) = ab + ac$.
\end{itemize}
\end{definition}
Roughly, all of the above mean that you have notions of $+$, $-$, $\times$ and $\div$ just as for regular real numbers.

Fields are a very beautiful structure; some examples are rational numbers~$\mathbb{Q}$, real numbers $\mathbb{R}$, and complex numbers~$\mathbb{C}$. These examples are infinite, however this does not necessarily have to be the case. 
The smallest example of a field has just two elements, $\mathbb{Z}_2=\{0,1\}$ or {\it bits}. The rules for addition and multiplication 
are the usual ones save that
$$
1+1=0\, .
$$

%Let $q \geq 0$ and let $\mathbb{Z}_q$ be the set of remainders of $\mathbb{Z}$ (the set of integers) by dividing by $q$. We say $\mathbb{Z}_q$ is the set of all $a$ modulo $q$ or $a \mod q$ for short or $a \equiv q$ where $a \in \mathbb{Z}$, and we define addition and multiplication to be their usual counterparts in $\mathbb{Z}$ except we take the result mod $q$. So for example we have $\mathbb{Z}_2 = \{0, 1\}$ where $1 + 1 = 2 \equiv 0$ (these are exactly the \hyperlink{bits}{bits} used in bit matrices) and  $\mathbb{Z}_3 = \{0, 1, 2\}$ with $1 + 1 = 2$, $2 \cdot 2 = 4 \equiv 1$. Now if $p$ is a prime number, then $\mathbb{Z}_p$ is a field (often written as $\mathbb{Z}_p$). Clearly $\mathbb{Z}_2$ is a field, and from above for $\mathbb{Z}_3$ we have $2^{-1} = 2$, so $\mathbb{Z}_3$ is also a field. For $\mathbb{Z}_5$ we have $2^{-1} = 3$ since $2\cdot 3 = 6 \equiv 1$ and $4^{-1} = 4$ since $4 \cdot 4 = 16 \equiv 1$. Often when $q = p^n$ where $p$ is a prime, then people will write $\mathbb{F}_q$ to reinforce that it is a field.

%In fact, for every prime number $p$, the set $\mathbb{Z}_p=\{0,1,\ldots, p-1\} $ forms a field.  The addition and multiplication are obtained by using the usual operations over the integers, and then dividing by $p$ and taking the remainder.  For example, in $\mathbb{Z}_5$, we have $4+3=2$, and $4\cdot4=1$.  (This is sometimes called ``clock arithmetic.'')  Such fields are very important in computer science, cryptography, and number theory.


%\subsection{Rings}
%\label{rings}
%
%However $\mathbb{Z}_4$ is not a field since $2 \cdot 2 = 4 \equiv 0$ and $2 \cdot 3 = 6 \equiv 2$. Similarly $\mathbb{Z}$ is not a field since $2$ does not have a multiplicative inverse.  These are known as \emph{rings}. For rings all of the addition axioms hold, but none of the multiplicative ones must.
%
%\begin{definition}
%\index{Ring}
%A \emph{ring} $R$ is a set with two operations $+$ and $\cdot$ that for all $a, b, c \in R$ the following axioms are satisfied:
%\begin{itemize}
%\item[A1.] Addition is associative $(a + b) + c = a + (b + c)$.
%
%\item[A2.] There exists an additive identity $0$.
%
%\item[A3.] Addition is commutative $a + b = b + a$.
%
%\item[A4.] There exists an additive inverse $-a$.
%
%\item[D.] The distributive law holds $a \cdot (b + c) = a \cdot b + a \cdot c$ and $(a + b) \cdot c = a \cdot c + b \cdot c$.
%\end{itemize}
%\end{definition}
%Note that when we have axiom~M3, then the two equations in axiom~D are equivalent.
%
%Clearly all fields are rings, but rings in general are not nearly as nice (for example, in $\mathbb{Z}_4$ two things can be multiplied together to give you $0$). An important example of a ring is $\mathbb{F}[x]$, which is the ring of all polynomials in one variable $x$ with coefficients in a field $\mathbb{F}$. Recall that you can do everything you want in a field except divide polynomials, but if you take the modulus with respect to a polynomial which is not a product of two smaller polynomials, you can get a field. We call such polynomials \emph{irreducible}. In other words, you take a polynomial $p$ and you set $p \equiv 0$, thus this is just making sure you don't have $ab \equiv 0$. For example, the polynomial $p(x) = x^2 + 1$ cannot be factored over $\mathbb{R}$ (i.e. with real coefficients), so what you get is actually the same field as $\mathbb{C}$ since we have $x^2 + 1 = 0$ or perhaps more suggestively $x^2 = -1$. This is what is known as a \emph{field extension}; these are the central objects in Galois theory\index{Galois} and are denoted $\mathbb{F}(\alpha)$ where $\alpha$ is a root of $p$.
%
%One final definition: We say that a field $\mathbb{F}$ has characteristic $p$ if $\sum_{i=1}^p 1 \equiv 0$ ({\it i.e.} we sum 1 together $p$ times and return to 0). For example $\mathbb{Z}_3$ has characteristic 3 since $1 + 1 + 1 \equiv 0$, and in general $\mathbb{Z}_p$ has characteristic $p$.
%
%A good exercise is to find an irreducible degree 2 polynomial $p$ in $\mathbb{Z}_2[x]$, and check that the field extension $\mathbb{Z}_2(\alpha)$ has 4 elements and has characteristic~2 (hence it is not actually $\mathbb{Z}_4$).
%
%\subsection{Algebras}
%\label{algebras}
%
%\begin{definition}
%\index{Algebra}
%An \emph{algebra} $A$ is a vector space over $\mathbb{F}$ with the operation $\cdot$ such that for all $u, v, w \in A$ and $\alpha, \beta \in \mathbb{F}$, we have
%\begin{itemize}
%\item[D.] The distributive law holds $u \cdot (v + w) = u \cdot v + u \cdot w$ and  $(u + v) \cdot w = u \cdot w + v \cdot w$.
%
%\item[S.] We have $(\alpha v) \cdot (\beta w) = (\alpha \beta)(v \cdot w)$.
%\end{itemize}
%\end{definition}
%Essentially an algebra is a ring that is also a vector space over some field. Or in simpler words,
%an algebra is a vector space where you can multiply vectors.
%
%For example, all $n \times n$ real matrices $M_n(\mathbb{R})$ is a ring but we can let scalars in $\mathbb{R}$ act on these matrices in their usual way. Another algebra is we can take $M_n(\mathbb{R})$ but take scalars in $\mathbb{C}$ and just formally say $i M$ is another element in this algebra. Another example is $\mathbb{R}^3$ where multiplication is the cross-product $\times$. We note that this is not associative nor commutative under $\times$ and that $v \times v = 0$ (so there are in fact no multiplicative inverses), and there is no multiplicative identity. Lastly, recall that $\mathfrak{sl}_n$ \hyperlink{scripts_properties_of_matrices_trace}{defined here} is an algebra under $[ , ]$.

\newpage
