


\begin{enumerate}

\item 
Consider an arbitrary matrix $M:\Re^m\to \Re^n.$
\begin{enumerate}
\item Argue that $Mx=0$ if only if $x$ is perpendicular to all columns of~$M^T$.
\item Argue that $Mx=0$ if only if $x$ is perpendicular to all of the linear combinations of the columns of $M^T$.
\item Argue that $\ker M$ is perpendicular to ${\rm ran} \,M^T$. 
\item Argue further $\Re^m=\ker M \oplus {\rm ran}\, M^T$. 
\item Argue analogously that $\Re^n=\ker M^T \oplus {\rm ran}\, M$. 
\end{enumerate} 
The equations in the last two parts describe how a linear transformation $M:\Re^m\to \Re^n$ determines orthogonal decompositions of both it's domain and target. This result sometimes goes by the humble name {\bf{The Fundamental Theorem of Linear Algebra}}\index{Fundamental Theorem of Linear Algebra}.

%\phantomnewpage


%\item Projection Matrices. 

\item \label{injectivekernalprob} Let $L \colon V\rightarrow W$ be a linear transformation.  Show that $\ker L=\{0_V\}$ if and only if $L$ is one-to-one:
\begin{enumerate}
\item {\it (Trivial kernel $\Rightarrow$ injective.)} Suppose that \(\ker L=\{0_V\}\). Show that \(L\) is one-to-one. Think about methods of proof--does a proof by contradiction, a proof by induction, or a direct proof seem most appropriate?
\item {\it (Injective $\Rightarrow$ trivial kernel.)} Now suppose that \(L\) is one-to-one. Show that \(\ker L=\{0_V\}\). That is, show that \(0_V\) is in \(\ker L\), and then show that there are no other vectors in \(\ker L\).
\end{enumerate}
\Videoscriptlink{kernel_range_nullity_rank_hint.mp4}{Hint}{scripts_kernel_range_nullity_rank_hint}
\phantomnewpage

\item Let $\{v_1, \ldots, v_n  \}$ be a basis for $V$ and $L:V\to W$ is a linear function. Carefully explain why
\[
L(V)=\spa \{Lv_1, \ldots, Lv_n \}\, .
\]


\phantomnewpage

\item Suppose $L \colon \Re^4\rightarrow \Re^3$ whose matrix $M$ in the standard basis is row equivalent to the following matrix:
\[
\begin{pmatrix}
1&0&0&\!-1\\
0&1&0&1\\
0&0&1&1\\
\end{pmatrix}={\rm RREF}(M)\sim M.
\]
\begin{enumerate}
\item \emph{Explain} why the first three columns of the original matrix $M$ form a basis for $L(\Re^4)$.
\item \emph{Find and describe} an algorithm (\textit{i.e.}, a general procedure) for computing a basis for $L(\Re^n)$ when $L \colon \Re^n\rightarrow \Re^m$. 
\item{\it Use} your algorithm to find a basis for \(L(\Re^4)\) when \(L \colon \Re^4 \to \Re^3\) is the linear transformation whose matrix \(M\) in the standard basis is
\[
\begin{pmatrix}
2&1&1&4\\
0&1&0&5\\
4&1&1&6\\
\end{pmatrix}.
\]
\end{enumerate}

\phantomnewpage

\item Claim: 
\begin{quote}If $\{v_1, \ldots, v_n  \}$ is a basis for $\ker L$, where $L \colon V\rightarrow W$, then it is always possible to extend this set to a basis for $V$.\end{quote}  
Choose some simple yet non-trivial linear transformations with non-trivial kernels and verify the above claim for those transformations.

\phantomnewpage

\item Let $P_n(x)$ be the space of polynomials in $x$ of degree less than or equal to $n$, and consider the derivative operator $$\frac{d}{dx}:P_n(x)\to P_n(x)\, .$$ %
Find the dimension of the kernel and image of this operator. What happens if the target space is changed to $P_{n-1}(x)$ or $P_{n+1}(x)$?

Now consider $P_2(x,y)$, the space of polynomials of degree two or less in $x$ and $y$.  (Recall how degree is counted; $xy$ is degree two, $y$ is degree one and $x^2y$ is degree three, for example.)  Let 
$$L:=\frac{\partial}{\partial x}+\frac{\partial}{\partial y}:P_2(x,y) \to P_2(x,y).$$  
(For example, $L(xy)=\frac{\partial}{\partial x}(xy)+\frac{\partial}{\partial y}(xy) = y+x$.)  Find a basis for the kernel of $L$.  Verify the dimension formula in this case.

\phantomnewpage

\item %(Extra credit) 
Lets demonstrate some ways the dimension formula can break down if a vector space is infinite dimensional.
\begin{enumerate}
\item Let $\mathbb{R}[x]$ be the vector space of all polynomials  in the variable~$x$ with real coefficients. Let $D = \frac{d}{dx}$ be the usual derivative operator. Show that the range of $D$ is $\mathbb{R}[x]$. What is $\ker D$?

\emph{Hint: Use the basis $\{ x^n \mid n \in \mathbb{N} \}$.}

\item Let $L \colon \mathbb{R}[x] \rightarrow \mathbb{R}[x]$ be the linear map $$L(p(x)) = xp(x)\, .$$  What is the kernel and range of $M$?

%\item Let $\ell^1$ be the vector space of all absolutely convergent sequences $s = \{ s_i \}$. Define the map $P \colon \ell^1 \rightarrow \ell^1$ by
%\[
%s_i \mapsto \begin{cases}
%  s_i & \text{if $i$ is even} \\
%  0 & \text{if $i$ is odd,}
%\end{cases}
%\]
%and for example
%\[
%P((1, 0, 0, \ldots)) = (0, 0, 0, \ldots), \hspace{20pt} P((0, 1, 0, \ldots)) = (0, 1, 0, \ldots).
%\]
%Show that $P$ is linear, is a projection (i.e. $P^2 = P$), has a kernel of infinite dimension, and has a range of infinite dimension.

%\emph{Hint: Define $e_i$ as the sequence with a 1 in the $i$-th position and 0 everywhere else which you can think of as a standard basis vector. What is $P(e_i)$ when $i$ is even? When $i$ is odd?}

\item Let $V$ be an infinite dimensional vector space and $L \colon V \rightarrow V$ be a linear operator. Suppose that $\dim \ker L < \infty$, show that $\dim L(V)$ is infinite. Also show that when $\dim L(V) < \infty$ that $\dim \ker L$ is infinite.
\end{enumerate}

\item This question will answer the question, ``If I choose a bit vector \emph{at random}\index{Random}, what is the probability that it lies in the span of some other vectors?''

\begin{itemize}
\item[$i.$] Given a collection $S$ of $k$ bit vectors in $B^3$, consider the bit matrix~$M$ whose columns are the vectors in $S$.  Show that $S$ is linearly independent if and only if the kernel of $M$ is trivial, namely the set ${\rm ker}M=\{v\in B^3| \, Mv=0\}$ contains only the zero vector.

\item[$ii.$] Give some method for choosing a random bit vector $v$ in \(B^3\).  Suppose $S$ is a collection of $2$ linearly independent bit vectors in $B^3$.  How can we tell whether $S\cup \{v\}$ is linearly independent?  Do you think it is likely or unlikely that $S\cup \{v\}$ is linearly independent?  Explain your reasoning.

\item[$iii.$] If \(P\) is the characteristic polynomial of a \(3 \times 3\) bit matrix, what must the degree of \(P\) be? Given that each coefficient must be either 0 or 1, how many possibilities are there for \(P\)? How many of these possible characteristic polynomials have 0 as a root? If \(M\) is a \(3 \times 3\) bit matrix chosen at random, what is the probability that it has 0 as an eigenvalue? (Assume that you are choosing a random matrix \(M\) in such a way as to make each characteristic polynomial equally likely.) What is the probability that the columns of \(M\) form a basis for \(B^3\)? (Hint: what is the relationship between the kernel of \(M\) and its eigenvalues?)

\item[Note:] We could ask the same question for real vectors: If I choose a real vector at random, what is the probability that it lies in the span of some other vectors? In fact, once we write down a reasonable way of choosing a random real vector, if I choose a real vector in \(\Re^n\) at random, the probability that it lies in the span of \(n-1\) other real vectors is zero! 
\end{itemize}

\end{enumerate}

%\phantomnewpage