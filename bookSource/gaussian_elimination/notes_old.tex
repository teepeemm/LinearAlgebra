\section{\gaussElimTitle}

\label{gaussElim}

You have seen that systems of linear equations can be written as matrix equations.
You will see that Gaussian elimination is an efficient shorthand for (maximally) simplifying a system of linear equations (or matrix equation).

<<<<<<< .mine
\moduletext{In \Lecture~\ref{warmup} we }{We just---thanks to the oranges and apples---}studied the linear system 
=======
%You might get the feeling that you are learning to do Gaussian elimination only so that you can tell your computer how too do it in the future. There is more than that going on here. Let us foreshadow chapter 3; as we attempt to streamline the process of elimination we will discover the building blocks of matrices. 
>>>>>>> .r2489



%In \Lecture~\ref{warmup}  we looked performed elimination on a system of equations. 
%It was nice to do this elimination by adding subtracting an multiplying wholes equations at a time. 
%Lets do another example with the system
%\begin{eqnarray}
%	x\ +\ y & = & 27\nn \\
%	2x-\ y & = &\  0\nn \,.
%\end{eqnarray}
%Adding the first equation to the second then dividing by 3 gives
%\begin{eqnarray}
%	x\ +\ 0 & = & 9\nn \\
%	2x-\ y & = &\  0\nn \,.
%\end{eqnarray}
%Subtracting rice the first from the second then dividing by $-1$ gives
%\begin{eqnarray}
%	x \phantom{\ +\ y}& = &\  9\nn \\
%	\phantom{x\ +\ }y & = & 18\, .\nn
%\end{eqnarray}
%
%\noindent
%The maximum number of terms have been eliminated from each equation, and the result is an obvious statement of the solution. 
%\\
%
%We also learned to write such a linear system using a matrix and two vectors. In this case the original linear system can be written
%
%\begin{equation*}
%    \begin{pmatrix}
%      1             &1  \\
%      2             &-1
%    \end{pmatrix}
%  \colvec{x \\ y}
%  =
%  \colvec{27 \\ 0}\, .
%\end{equation*}
%
%
%\noindent
%Likewise, the system of equations that we obtained after elimination can be written
%
%\begin{equation*}
%    \begin{pmatrix}
%      1             &0  \\
%      0             &1
%    \end{pmatrix}
%  \colvec{x \\ y}
%  =
%  \colvec{9 \\ 18} \, .
%\end{equation*}
%\\
%
%%\noindent
%By the way, the matrix $$I=    \begin{pmatrix}
%      1             &0  \\
%      0             &1
%    \end{pmatrix}$$ is called the \emph{Identity Matrix}\index{Identity matrix!$2\times2$}.  She will be very important to us. You should check that if $v$ is any vector, then $$Iv=v\, .$$
%    
%Here is a nice way to summarize your goal when performing the process we are calling elimination elimination; manipulate the system of equations until the resulting system can be written as a matrix equation with the identity matrix.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Augmented Matrix Notation for Linear Systems}

%A useful shorthand for a  system of linear equations is an \hypertarget{augmented_matrix}{\emph{Augmented Matrix}}\index{Augmented matrix~$2\times2$}. 
We will introduce this notation through examples: 
The linear system 
\begin{eqnarray}
	x\ +\ y & = & 27\nn \\
	2x-\ y & = &\  0\nn \,
\end{eqnarray}
is denoted by the augmented matrix

\[
\begin{amatrix}{2}
1 &1 &27 \\ 2 &-1 & 0
\end{amatrix}
\]

\noindent
This is truly minimalist notation. It is even more minimal then the matrix notation  
\begin{equation*}
    \begin{pmatrix}
      1             &1  \\
      2             &-1
    \end{pmatrix}
  \colvec{x \\ y}
  =
  \colvec{27 \\ 0}\, .
\end{equation*}
All three of the above equations denote the same thing. 


\videoscriptlink{gaussian_elimination_more_background.mp4}{Augmented Matrix Notation}{script_gaussian_elimination_more}

Going up in size,
the system
\begin{eqnarray*}
1x + 3y + 2z + 0w   =9 \\ 
6x + 2y + 0z   -2w  =0  \\
-1x+ 0 y + 1 z + 1w  =3 
\end{eqnarray*}
is denoted by the augmented matrix
\[
\begin{amatrix}{4}
1 & 3 & 2 & 0  & 9 \\ 
6 & 2 & 0  & -2 & 0  \\
-1& 0  & 1  & 1 & 3
\end{amatrix}
\]
%When writing a system of equations one can write out the terms with zero for coefficients or not
%\begin{eqnarray*}
%1x + 3y + 2z  \phantom{+ 0w}   =9 \\ 
%6x + 2y \phantom{ + 0z}   -2w  =0  \\
%-1x  \phantom{+0 y} + 1 z + 1w  =3 
%\end{eqnarray*}
As a matrix equation the system reads
\begin{eqnarray*}
\left(\begin{array}{cccc}
1 & 3 & 2 & 0   \\ 
6 & 2 & 0  & -2   \\
-1& 0  & 1  & 1 
\end{array}\right)
\colvec{ x\\ y\\z\\w}
=\colvec{ 9\\0\\3}
\end{eqnarray*}




Here's the general case:  The number of equations in the linear system is the number of rows $r$ in the augmented matrix, and the number of columns $k$ in the matrix left of the vertical line is the number of unknowns.
\[
\begin{amatrix}{4}
a^1_1 & a^1_2 & \cdots & a^1_k & b^1 \\ 
a^2_1 & a^2_2 & \cdots & a^2_k & b^2 \\ 
\vdots & \vdots & & \vdots & \vdots  \\
a^r_1 & a^r_2 & \cdots & a^r_k & b^r \\ 
\end{amatrix}
\]

\reading{2}{1}
%\href{\webworkurl ReadingHomework2/1/}{Reading homework: problem 2.1}
Make sure you can write out the system of equations and the associated matrix equation for any augmented matrix. 
\\


<<<<<<< .mine
\subsection*{Equivalence Relations for Linear Systems}
=======
>>>>>>> .r2489

We now have three ways or writing the same question. 
Lets write them side by side as we solve the system using a nice algebra trick: we will strategically add and subtract  equations.

\begin{example} of how equations, matrix equations, and augmented matrices change during elimination
\begin{eqnarray*}
   \left.
\begin{array}{lcr}
	x\ +\ y & = & 27 \\
	2x-\ y & = &\  0 
     \end{array}
   \right\} 
   \Leftrightarrow
    \begin{pmatrix}
      1             &1  \\
      2             &-1
    \end{pmatrix}
  \colvec{x \\ y}
  =
  \colvec{27 \\ 0}
  \Leftrightarrow
 \begin{amatrix}{2}
1 &1 &27 \\ 2 &-1 & 0
\end{amatrix}
  \end{eqnarray*}
Let the new first equation be the sum of the first and second equations
\begin{eqnarray*}
   \left.
\begin{array}{lcr}
	3x\ +\ 0 & = & 27 \\
	2x-\ y & = &\  0 
     \end{array}
   \right\} 
   \Leftrightarrow
    \begin{pmatrix}
      3             &0  \\
      2             &-1
    \end{pmatrix}
  \colvec{x \\ y}
  =
  \colvec{27 \\ 0}
  \Leftrightarrow
 \begin{amatrix}{2}
3 &0 &27 \\ 2 &-1 & 0
\end{amatrix}
  \end{eqnarray*}
Let the new first equation be the old first equation divided by 3
 \begin{eqnarray*}
   \left.
\begin{array}{lcr}
	x\ +\ 0 & = & 9 \\
	2x-\ y & = &\  0 
     \end{array}
   \right\} 
   \Leftrightarrow
    \begin{pmatrix}
      1             &0  \\
      2             &-1
    \end{pmatrix}
  \colvec{x \\ y}
  =
  \colvec{9 \\ 0}
  \Leftrightarrow
 \begin{amatrix}{2}
1 &0 &9 \\ 2 &-1 & 0
\end{amatrix}
  \end{eqnarray*}
Let the new second equation be the old second equation minus two times the first equation 
\begin{eqnarray*}
   \left.
\begin{array}{lcr}
	x\ +\ 0 & = & 9 \\
	0-\ y & = &\  -18
     \end{array}
   \right\} 
   \Leftrightarrow
    \begin{pmatrix}
      1             &0  \\
      0             &-1
    \end{pmatrix}
  \colvec{x \\ y}
  =
  \colvec{9 \\ -18}
  \Leftrightarrow
 \begin{amatrix}{2}
1 &0 &9 \\ 0 &-1 & -18
\end{amatrix}
  \end{eqnarray*}
Let the new  second equation be the old second equation divided by -1
\begin{eqnarray*}
   \left.
\begin{array}{lcr}
	x + 0 & = & \ 9 \\
	0 + y & = &  18
     \end{array}
   \right\} 
   \Leftrightarrow
    \begin{pmatrix}
      1             &0  \\
      0             &1
    \end{pmatrix}
  \colvec{x \\ y}
  =
  \colvec{9 \\ 18}
  \Leftrightarrow
 \begin{amatrix}{2}
1 &0 &9 \\ 0 &1 & 18
\end{amatrix}
  \end{eqnarray*}
\end{example}
Do you see what the strategy was? To eliminate $y$ from the first question and then eliminate $x$ from the second. The result was a plain statement of the solution. But the quantity of writing here was atrocious. 

Here is the big idea: 
Everywhere in the the instructions we can replace the word ``equation" with the word ``row" and interpret the instructions as telling us what to do with the augmented matrix instead of the system of equations.
The result is a process called called {\it Gaussian elimination}\index{Gaussian elimination}: 

\begin{example} of Gaussian elimination
\begin{eqnarray*}
 \begin{amatrix}{2}
1 &1 &27 \\ 2 &-1 & 0
\end{amatrix}
  \end{eqnarray*}
Let the new first row be the sum of the first and second rows
\begin{eqnarray*}
 \begin{amatrix}{2}
3 &0 &27 \\ 2 &-1 & 0
\end{amatrix}
  \end{eqnarray*}
Let the new first row be the old first row divided by 3
 \begin{eqnarray*}
 \begin{amatrix}{2}
1 &0 &9 \\ 2 &-1 & 0
\end{amatrix}
  \end{eqnarray*}
Let the new second row be the old second row minus two times the first row 
\begin{eqnarray*}
 \begin{amatrix}{2}
1 &0 &9 \\ 0 &-1 & -18
\end{amatrix}
  \end{eqnarray*}
Let the new  second row be the old second row divided by -1
\begin{eqnarray*}
 \begin{amatrix}{2}
1 &0 &9 \\ 0 &1 & 18
\end{amatrix}
  \end{eqnarray*}
The solution can be read off very quickly, and the notation was very minimal. 
\end{example}
 At each step, the augmented matrices encode systems of equations which have the same solutions. Lets make this idea more formal, and introduce some notation to convey the idea.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Equivalence and the act of Solving}

%A small (but fun) excursion into the philosophy of mathematical notation might help here: 
%It often happens that two mathematical objects will appear to be different but in fact are exactly the same.  The best-known example of this are fractions.  
%For example, the fractions $\frac{1}{2}$ and $\frac{6}{12}$ describe the same number. You would certainly call these fractions equivalent. Suppose I have a large pile of equivalent fractions, such as $\frac{2}{4}$, $\frac{27}{54}$, $\frac{100}{200}$, and so on.  Most people will agree that their favorite way to write the number represented by all these different factors is $\frac{1}{2}$, in which the numerator and denominator are relatively prime.  We usually call this a \emph{reduced fraction}.  This is an example of a \emph{canonical form}, which is an extremely impressive way of saying ``our favorite way of writing it down''.  
%As you know, every fraction is equivalent to a reduced fraction, 
%and furthermore, that reduced fraction is \emph{unique}. This is the canonical form form fractions.  
%You learned the process to get to this canonical form for the fraction long ago; it looks like 
%$\frac{6}{12}=\frac{2\cdot3}{2\cdot6}=\frac{3}{6}=\frac{3\cdot1}{3\cdot2}=\frac{1}{3}$.
%\\
%
%
%Similarly, in our running example, we've noticed that many augmented matrices including
%
%\[
%\begin{amatrix}{2}
%1 &1 &27 \\ 2 &-1 & 0
%\end{amatrix}
%,\qquad
%\begin{amatrix}{2}
%1 &0 &9 \\ 2 &-1 & 0
%\end{amatrix}
%,\qquad
%\begin{amatrix}{2}
%1 &0 &9 \\0   & 1 & 18
%\end{amatrix}
%\]
%contain the same information: $x=9, y=18$.  
Two augmented matrices corresponding to linear systems 
%{\it that actually have solutions} %cmon, this idea has not even been introduced
are said to be \hypertarget{roweq}(row) 
\emph{equivalent}\index{Row equivalence} if they have the \emph{same} solutions.
To denote this we introduce the symbol $\sim$ which is called ``tilde" but should be read as  ``is equivalent to''. For example we found above that
\[
\begin{amatrix}{2}
1 &1 &27 \\ 2 &-1 &0
\end{amatrix}
\sim
\begin{amatrix}{2}
1 &0 &9 \\ 2 &-1 & 0
\end{amatrix}
\sim
\begin{amatrix}{2}
1 & 0&9 \\   0& 1 & 18
\end{amatrix}
\]
and certainly the last of these is our favorite!
\videoscriptlink{gaussian_elimination_background.mp4}{Equivalence Example}{script_gaussian_elimination_background}

\videoscriptlink{gaussian_elimination_3_3_example.mp4}{A $3 \times 3$ example}{scripts_gaussian_elimination_3_3_example}

Setting up a string of equivalences like this is actually a means of solving systems of linear equations. This is the main idea of this chapter.

\begin{example} (Using Gaussian elimination to solve a system of linear equations)
\begin{eqnarray*}
   \left.
\begin{array}{lcr}
	x +\ y & = & 5 \\
	x + 2y & = &\  8
     \end{array}
   \right\} 
   \Leftrightarrow
\begin{amatrix}{2}
1 &1 &5 \\ 1 &2 & 8
\end{amatrix}
\sim
\begin{amatrix}{2}
1 &1 &5 \\ 0 &1 & 3
\end{amatrix}
\sim
\begin{amatrix}{2}
1 &0 &2 \\ 0 &1 & 3
\end{amatrix}
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x + 0 & = & 2 \\
	 0 + y & = &\  3
     \end{array}
   \right.
\end{eqnarray*}  
Note that we used the top left $1$ to make the bottom left entry zero. For this reason we call that number a pivot; imagine a wiper blade hanging down form the top left slot wiping the lower left slot away. Similarly the bottom right slot was used to wipe away the top right slot, so it is called a pivot. 
\end{example}

This {\it pivot} jargon is helpful for describing the goings on in Gaussian elimination. Be sure you understand the idea before moving on. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reduced Row Echelon Form}
The goal in Gaussian elimination is to have the part of the augmented matrix left of the dividing line become the matrix
 $$I=    \begin{pmatrix}
      1             &0  \\
      0             &1
    \end{pmatrix}$$ 
This is called the \emph{Identity Matrix}\index{Identity matrix!$2\times2$}.  
(She will be very important to us, along with her bigger sisters.)
%You should check that if $v$ is any vector, then $Iv=v\, .$, that is, the identity matrix is the operator that maps any vector to itself. Identity is a good name for her!) 
%
%Hopefully we have tempted you to think that, just as there is a canonical form for fraction (reduced form) there is a canonical form of augmented matrices. There is; that canonical form is called Reduced Row Echelon Form (or RREF for short), the subject of the next section. 
%Unfortunately, we may have tempted you to think that that canonical form always involves the identity matrix left of the dividing line. 
This can't always be done.
%The situation is a bit more complicated for a variety of reasons. Some examples will elucidate them.

\begin{example} (Redundant equations)
 \begin{eqnarray*}
   \left.
\begin{array}{lcr}
	\ x + \ y & = & 2 \\
	2x + 2y & = &  4
     \end{array}
   \right\} 
   \Leftrightarrow
\begin{amatrix}{2}
1 &1 &2 \\ 2 &2 & 4
\end{amatrix}
\sim
\begin{amatrix}{2}
1 &1 &2 \\ 0 &0 & 0
\end{amatrix}
%\sim
%\begin{amatrix}{2}
%1 &0 &2 \\ 0 &1 & 3
%\end{amatrix}
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x + y & = & 2 \\
	 0 + 0 & = &  0
     \end{array}
   \right.
\end{eqnarray*}  
This example demonstrates if one equation is a multiple of the other the identity matrix can not be a reached. This is because the first step in elimination will make the second row a row of zeros. Notice that solutions still exists $x=1,y=1$ is a solution. The last augmented matrix here is in RREF.
\end{example}

\begin{example} (Inconsistant equations)
 \begin{eqnarray*}
   \left.
\begin{array}{lcr}
	\ x + \ y & = & 2 \\
	2x + 2y & = &  5
     \end{array}
   \right\} 
   \Leftrightarrow
\begin{amatrix}{2}
1 &1 &2 \\ 2 &2 & 5
\end{amatrix}
\sim
\begin{amatrix}{2}
1 &1 &2 \\ 0 &0 & 1
\end{amatrix}
%\sim
%\begin{amatrix}{2}
%1 &0 &2 \\ 0 &1 & 3
%\end{amatrix}
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x + y & = & 2 \\
	 0 + 0 & = &  1
     \end{array}
   \right.
\end{eqnarray*}  
This system of equation has a solution if there exists two numbers $x$, and $y$ such that $0+0=1$. That is a tricky way of saying there are no solutions. The last form of the augmented matrix here is in RREF.
\end{example}


\begin{example} (Silly order of equations)\\
A robot might make the following mistake
 \begin{eqnarray*}
   \left.
\begin{array}{lcr}
	0x +  \ y & = & -2 \\
	\ x + y & = &  7
     \end{array}
   \right\} 
   \Leftrightarrow 
\begin{amatrix}{2}
0 &1 & -2\\ 1 &1 & 7
\end{amatrix}
\sim \cdots
\end{eqnarray*}  
and then give up because the the upper left slot can not function as a pivot since the 0 that lives there can not be used to eliminate the zero below it. Of course, the right thing to do is to change the order of the equations before starting
 \begin{eqnarray*}
   \left.
\begin{array}{lcr}
	\ x + y & = &  7
	\\
	0x +  \ y & = & -2 
	     \end{array}
   \right\} 
   \Leftrightarrow
\begin{amatrix}{2}
1 &1 & 7\\ 0 &1 & -2
\end{amatrix}
\sim 
\begin{amatrix}{2}
1 &0 & 9\\ 0 &1 & -2
\end{amatrix}
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x + 0 & = & 9 \\
	 0 + y & = & -2
     \end{array}
   \right.
\end{eqnarray*}  
The third appearance of an augmented matrix here is RREF of the first, and second. That is to say, you can swap rows on your way to RREF.
\end{example}



For larger systems of matrices, these three kinds of problems are the obstruction to obtaining the identity matrix.% left of the divide in Gaussian elimination. 
If we allow reordering of equations before going to augmented matrix, then 
\emph{Reduced Row Echelon Form}\index{Reduced row echelon form} (RREF) typically looks like 
\[
\begin{amatrix}{7}
1       	& * & 0		& * & 0		& \cdots& 0		& b^1 \\ 
0	        & 0 & 1		& * & 0		& \cdots& 0		& b^2 \\
0		& 0& 0		& 0 & 1		& \cdots& 0		& b^3 \\  
\vdots  	& \vdots& \vdots	&   & \vdots	& 	& 0			& \vdots \\  
		& &			&  &			&      & 1			& b^k \\  
0		& 0 & 0		& 0 & 0		& \cdots& 0 		& b^{k+1} \\ 
\vdots  	& \vdots & \vdots	&  \vdots & \vdots	& 	& \vdots		& \vdots \\  
0		&  0 & 0		& 0 & 0		& \cdots& 0		& b^r \\ 
\end{amatrix}
\]

%The first non-zero entry in each row is called the \emph{pivot}\index{Pivot}.    
\noindent
The asterisks denote the possibility of an arbitrary number of a nonexistent column. (For e.g. the identity matrix is obtained by having all asterisks denote nonexistent columns.) 
If any of the numbers $b^{k+1},\dots b^r$ are non-zero then the system of equations is inconsistent and has no solutions. 


Think about it how to get to this form in general; we can do the following three things corresponding to exchanging the order of equations, multiplying one equation by a constant or adding equations:
\begin{itemize}
\item Exchange rows
\item Multiply a row by a constant
\item Add or subtract rows
\end{itemize}
Those three are called the elementary row operations, the subject of the next lecture. 
They can be used to obtain  RREF by the following procedure
\begin{itemize}
\item Make the leftmost nonzero entry in the top row 1 by multiplication.  
\item Then use that 1 as a pivot to eliminate everything below it. 
\item Then go to the next row and make the leftmost non zero entry 1. 
\item Then use that 1 as a pivot to eliminate everything below {\it and above it}! 
\item Then go to the next row and make the leftmost nonzero entry 1... etc
\end{itemize}
The reason we need the asterisk is demonstrated in the ``redundant equations" example above. 
Actually, in full generality where we have asterisks one can have multiple numbers with columns of zeros below them, as one would have in the following

\begin{example} (Inconsistant equations)
 \begin{eqnarray*}
   \left.
\begin{array}{lcr}
	\ x \ + \ y + \ z +  0w & = & 2 \\
	2x + 2y +2z+2w & = &  4
     \end{array}
   \right\} 
   \Leftrightarrow
\begin{amatrix}{4}
1 &1 &1 & 0 &2 \\ 
2 &2 &2 & 1 & 4
\end{amatrix}
\\
\sim
\begin{amatrix}{4}
1 &1 &1 & 0 &2 \\ 
0 &0 &0 & 1 & 0
\end{amatrix}
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x + y +z& = & 2 \\
	 w & = &  0
     \end{array}
   \right.
\end{eqnarray*}  
Note that there was no hope of reaching the identity matrix just because of the shape of the augmented matrix we started with. 
\end{example}


\noindent
You may prefer a purely verbal description.
The following properties fully describe the RREF.

\begin{enumerate}
\item  In every row  the left most non-zero entry is  $1$ (and is a pivot).

\item The pivot of any given row is always to the right of the pivot of the row above it.

\item The pivot is the only non-zero entry in its column.
\end{enumerate}

\begin{example} (Augmented matrix in RREF)
$
\begin{amatrix}{3} 
1 & 0 & 7 & 0 \\ 
0 & 1 & 3 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 \\
\end{amatrix}
$
\end{example}

\begin{example} (Augmented matrix NOT in RREF)
$
\begin{amatrix}{3} 
1 & 0 & 3 & 0 \\ 
0 & 0 & 2 & 0 \\
0 & 1 & 0 & 1 \\
0 & 0 & 0 & 1 \\
\end{amatrix}
$\\
Actually, this NON-Example breaks all three of the rules!
\end{example}

\subsection{Solution Sets}
%While RREF is not always pretty, it is certainly useful. 
%Our goal  is to solve systems of linear equations. 
RREF represents a maximally simplified version of the original system of equations in the following sense: 
\begin{itemize}
\item As many coefficient of the variables have been set to zero as is possible 
\item As many coefficients of variables have been set to 1 as possible.
\end{itemize}
It is easier to read off solutions from the maximally simplified equations than from the original equations, even when there are infinitely many solutions.

\begin{example}
 \begin{eqnarray*}
\left.
\begin{array}{lcr}
	x  +y    \phantom{+ z}  + 5w & ~  = 1 \\
	\phantom {x+}  \ y  \phantom{+z}   + 2 w & = 6 \\
	\phantom{x+y+} z+         4w & = 8
\end{array}
 \right\}
 \Leftrightarrow
 \begin{amatrix}{4} 
1 & 1 & 0 & 5 & 1 \\ 
0 & 1 & 0 & 2 & 6 \\
0 & 0 & 1 & 4 & 8 
\end{amatrix}
\sim
 \begin{amatrix}{4} 
1 & 0 & 0 & 3 & -5 \\ 
0 & 1 & 0 & 2 & 6 \\
0 & 0 & 1 & 4 & 8 
\end{amatrix}
\\
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x \phantom{+y    + z}  + 3w & ~ \ = -5 \\
	\phantom {x+}   y \, \phantom{+z}  \ + 2 w & = 6 \\
	\phantom{x+y+} z+         4w & = 8
     \end{array}
     \right.
\end{eqnarray*}
In this case, we say that $x,y$, and $z$ are ``pivot variables" because they appear with pivots as coefficients. Since $w$ never appears with a pivot as a coefficient, 
we say that it is not a pivot variable. %We call it a free variable. 
One way to express the solutions to this system of equations is to put all the pivot variables on one side and all the non-pivot variables on the other side. It is also nice to add the ``freebee equation" $w=w$ to obtain the system
\begin{eqnarray*}
\left.
\begin{array}{lcr}
	x & = -5 -3w \\
	 y  & = 6 -2w\\
	 z & = 8-4w \\
	w & =\phantom{8-4}w          
     \end{array}
     \right\}
     \Leftrightarrow
\colvec{x\\y\\z\\w} = \colvec{-5\\6\\8\\0} + w\colvec{-3\\-2\\-4\\1}
\end{eqnarray*}
where we have written the solution to the corresponding matrix problem. There are infinitely many solutions, one for each value of $z$. We call the collection of all solutions {\it the solution set}\index{solution set}\index{solution set} It is easy to check that the solution corresponding to $w=0$ really does fit into the matrix equation. 
\end{example}


The last example demonstrated the standard approach to solving a system of linear equations in its entirety: write the augmented matrix, obtain RREF, return to the system of equations, and express the non-pivot variables in terms of the pivot variables. 
There are always exactly enough non-pivot variables to index your solutions. 
In any approach, the variables which are not expressed in terms of the other variables are called the {\it free variables}\index{free variables}. The standard approach is to use the non-pivot variables as free variables.

Non-standard approach: solve for $w$ in terms of $z$ and substitute into the other equations. You now have an expression for each component in terms of $z$. But why pick $z$ instead of $y$ or $x$? (or $x+y$?) The standard approach feels natural, and that is why it became the standard.

When you see a RREF augmented matrix with two columns that have no pivot, you know there will be two free variables. 

\begin{example}
 \begin{eqnarray*}
 \begin{amatrix}{4} 
1 & 0 & 7 & 0 & 4 \\ 
0 & 1 & 3 & 4 & 1 \\ 
0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 0 \\ 
\end{amatrix}
\Leftrightarrow
\left\{
\begin{array}{lcr}
	x \phantom{+y}    + 7z  \phantom{+w} & = 4 \\
	\phantom {x+}   y + 3z  {+4w} & = 1 \\
	%\phantom{x+y+z+}          w & = 2
     \end{array}
     \right.
\end{eqnarray*}  
Expressing the pivot variables in terms of the non-pivot variables, and using two freebee equations gives
\begin{eqnarray*}
\left.
\begin{array}{lcr}
	x & = 4 -7z \\
	 y  & = 1 -3z-2w\\
	 z         & = z\\
	w & =w          
     \end{array}
     \right\}
     \Leftrightarrow
\colvec{x\\y\\z\\w} = \colvec{4\\1\\0\\0} + z\colvec{-7\\-3\\1\\0} + w\colvec{0\\-2\\0\\1}
\end{eqnarray*}
There are infinitely many solutions. One solution for each pair of numbers $z,w$. 
\end{example}
You can imagine having three, four, or fifty-six non-pivot columns and the same number of free variables indexing your solutions set. You need to become very adept at reading off solutions of linear systems from the RREF
of their augmented matrix. 

%This example emphasizes different aspects.
%\begin{example}
%$$
%\begin{amatrix}{5} 
%1 & 1 & 0 & 1 & 0 & 1\\ 
%0 & 0 & 1 & 2 & 0 & 2\\ 
%0 & 0 & 0 & 0 & 1 & 3\\ 
%0 & 0 & 0 & 0 & 0 & 0
%\end{amatrix}\, .
%$$
%Here we were not told the names of the variables, so lets just call them $x_1,x_2,x_3,x_4,x_5$.
%(There are always as many of these as there are columns in the matrix before the vertical line; the number of rows,
%on the other hand is the number of linear equations.)
%
%To begin with we immediately notice that there are no pivots in the second and fourth columns so, as per the standard approach, we will be all variables in terms of $x_2$ and $x_4$. 
%Next we see from the second last row that $x_5=3$. The second row says 
%$x_3=2-2x_4=2-2 x_2$.
%The top row then gives $x_1=1-x_2-x_4=1-x_1-x_2$. Again we can write this solution as a vector
%$$
%\colvec{1\\0\\2\\0\\3}+x_1\colvec{-1\\1\\0\\0\\0}+x_2\colvec{-1\\0\\-2\\1\\0}\, .
%$$
%Observe, that since no variables were given at the beginning, we can use any symbols instead of $x_1$ and $x_2$. For example lower case greek letter lambda:
%$$
%\colvec{1\\0\\2\\0\\3}+\lambda_1\colvec{-1\\1\\0\\0\\0}+\lambda_2\colvec{-1\\0\\-2\\1\\0}\, .
%$$
%As a challenge, look carefully at this solution and make sure you can see how every part of it comes from
%the original augmented matrix without every having to reintroduce variables and equations.
%\end{example}
%
%




%\begin{theorem}
%Every augmented matrix is row-equivalent to a \emph{unique} augmented matrix in reduced row echelon form.
%\end{theorem}
%
%\noindent
%In \Lecture~\ref{elemRowOpsPath}, we will see why this is true.

<<<<<<< .mine
\begin{theorem}
Every augmented matrix is row-equivalent to a \emph{unique} augmented matrix in reduced row echelon form.
\end{theorem}

\noindent
\moduletext{In \Lecture~\ref{elemRowOpsPath}, we will see}{Later you will explore} why this is true.

=======
>>>>>>> .r2489
\References{

Hefferon, Chapter One, Section 1
\\
Beezer, Chapter SLE, Section RREF
\\
Wikipedia, \href{http://en.wikipedia.org/wiki/Row_echelon_form}{Row Echelon Form}}





\inputProblems{\gaussElimPath/problems}

\newpage


