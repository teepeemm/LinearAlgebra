\chapter{Sample First Midterm}

Here are some worked problems typical for what you might expect on a first midterm examination.
\label{sample1}

\begin{enumerate}
\item Solve the following linear system.  Write the solution set in vector form.  Check your solution.  Write one particular solution and one homogeneous solution, if they exist.  What does the solution set look like geometrically?
$$
\begin{array}{rrrrrr}
x &+&3y & &&= 4\\[1mm]
x &-& 2y &+& z &= 1\\[1mm]
2x &+&y &+& z &= 5\\[1mm]
\end{array}
$$

\item
Consider the system of equations
$$
\left\{
\begin{array}{rrrrrrrrr}
x&&&-&z&+&2w&=&-1\\[2mm]
x&+&y&+&z&-&w&=&2\\[2mm]
&-&y&-&2z&+&3w&=&-3\\[2mm]
5x&+&2y&-&z&+&4w&=&1\\[2mm]
\end{array}
\right. 
$$
\begin{enumerate}
\item Write an augmented matrix for this system.
\item Use elementary row operations to find its reduced row echelon form.
\item Write the solution set for the system in the form $$S=\{X_0+\sum_i \mu_i Y_i:\mu_i\in \mathbb R\} .$$
\item What are the vectors $X_0$ and $Y_i$ called {\it and} which matrix equations do they solve?
\item Check separately that $X_0$ and each $Y_i$ solve the matrix systems you claimed they solved in part (d).
\end{enumerate}

\item Use row operations to invert the matrix
$$
\begin{pmatrix}
1&2&3&4\\
2&4&7&11\\
3&7&14&25\\
4&11&25&50
\end{pmatrix}
$$

\item Let $M = \left ( \begin{array}{cc} 2 & 1 \\ 3 & -1 \end{array}  \right )$.  Calculate $M^TM^{-1}$.  Is $M$ symmetric?  What is the trace of the transpose of $f(M)$, where $f(x) = x^2 -1$?

\item In this problem $M$ is the matrix
$$
M=\begin{pmatrix}\cos\theta & \sin\theta \\ -\sin\theta&\cos\theta\end{pmatrix}
$$
and $X$ is the vector
$$
X=\begin{pmatrix}x\\y \end{pmatrix}\, .
$$
Calculate all possible dot products between the vectors $X$ and $MX$. Compute the lengths of $X$ and $MX$.
What is the angle between the vectors $MX$ and $X$. Draw a picture of these vectors in the plane. For what values
of $\theta$ do you expect equality in the triangle and Cauchy--Schwartz inequalities?

\item Let $M$ be the matrix
$$
\begin{pmatrix}
1&0&0&1&0&0\\
0&1&0&0&1&0\\
0&0&1&0&0&1\\
0&0&0&1&0&0\\
0&0&0&0&1&0\\
0&0&0&0&0&1
\end{pmatrix}
$$
Find a formula for $M^k$ for any positive integer power~$k$. Try some simple examples like $k=2,3$ if confused.



\item What does it mean for a function to be linear?  Check that integration is a linear function from $V$ to $V$, where $V = \{ f: \mathbb{R} \to \mathbb{R} \mid f \textrm{ is integrable}\}$ is a vector space over $\mathbb{R}$ with usual addition and scalar multiplication.


\item What are the four main things we need to define for a vector space?  Which of the following is a vector space over $\mathbb{R}$?  For those that are not vector spaces, modify one part of the definition to make it into a vector space.
\begin{enumerate}
\item $V = \{ \textrm{ $2 \times 2$ matrices with entries in $\mathbb{R}$} \}$, usual matrix addition, and $k \cdot \left ( \begin{array}{cc} a & b \\ c & d \end{array}  \right ) = \left ( \begin{array}{cc} ka & b \\ kc & d \end{array}  \right )$ for $k \in \mathbb{R}$.

\item $V = \{ \textrm{polynomials with complex coefficients of degree $\leq 3$} \}$, with usual addition and scalar multiplication of polynomials.

\item $V = \{ \textrm{vectors in $\mathbb{R}^3$ with at least one entry containing a 1}\}$, with usual addition and scalar multiplication.
\end{enumerate}


\item
{\it Subspaces:} If $V$ is a vector space, we say that $U$ is a {\it subspace} of $V$ when the set $U$ is also a vector space,
using the vector addition and scalar multiplication rules of the vector space $V$. 
(Remember that $U\subset V$  says that  ``$U$ is a subset of $V$'', {\it i.e.}, all elements of $U$
are also elements of $V$. The symbol $\forall$ means ``for all'' and $\in$ means ``is an element of''.)

\noindent
Explain why additive closure ($u+w\in U$ $\forall$ $u,v\in U$) and multiplicative closure ($r.u\in U$ $\forall$ $r\in \mathbb R$, $u\in V$) 
ensure that (i) the zero vector $0\in U$ and (ii) every $u\in U$ has an additive inverse.\\[2mm]

\noindent
In fact it suffices to check closure under addition and scalar multiplication to verify that $U$ is a vector space. Check whether the following
choices of $U$ are vector spaces:
\begin{enumerate}
\item
$U=\left\{\begin{pmatrix}x\\y\\0\end{pmatrix}:x,y\in \mathbb R\right\}$
\item
$U=\left\{\begin{pmatrix}1\\0\\z\end{pmatrix}:z\in \mathbb R\right\}$
\end{enumerate}

\item
Find an LU decomposition for the matrix 
$$
\begin{pmatrix}
1&1&-1&2\\
1&3&2&2\\
-1&-3&-4&6\\
0&4&7&-2
\end{pmatrix}
$$
Use your result to solve the system
$$
\left\{
\begin{array}{cccccccc}
x&+&y&-&z&+&2w&=7\\[1mm]
x&+&3y&+&2z&+&2w&=6\\[1mm]
-x&-&3y&-&4z&+&6w&=12\\[1mm]
&&4y&+&7z&-&2w&=-7
\end{array}
\right.
$$

\end{enumerate}

\subsection*{Solutions}

\begin{enumerate}
\item
{\it As an additional exercise, write out the row operations above the $\sim$ signs below.}
$$
\left(\begin{array}{rrr|r}
1&3&0&4\\[1mm]1&-2&1&1\\[1mm]2&1&1&5
\end{array}\right)
\sim
\left(\begin{array}{rrr|r}
1&3&0&4\\[1mm]0&-5&1&-3\\[1mm]0&-5&1&-3
\end{array}\right)
\sim
\left(\begin{array}{rrr|r}
1&0&\frac35&\frac{11}{5}\\[1mm]0&1&-\frac15&\frac35\\[1mm]0&0&0&0
\end{array}\right).
$$
Solution set is 
$$
\left\{\begin{pmatrix}x\\y\\ z\end{pmatrix}=\begin{pmatrix}\frac{11}5\\[1mm] \frac35\\ 0\end{pmatrix}+\mu
\begin{pmatrix}-\frac35\\\frac15\\1\end{pmatrix}\colon \mu \in \mathbb{R}
\right\}.
$$
Geometrically this represents a line in ${\mathbb R}^3$ through the point 
$\begin{pmatrix}\frac{11}5\\[1mm] \frac35\\ 0\end{pmatrix}$ 
running parallel to the vector 
$\begin{pmatrix}-\frac35\\[1mm]\frac15\\[1mm]1\end{pmatrix}$.

The vector 
$\ccolvec{\frac{11}5\\[1mm] \frac35\\ 0}$ 
is {\it a} particular solution 
and $\begin{pmatrix}-\frac35\\\frac15\\1\end{pmatrix}$
is {\it a} homogeneous solution. 

As a double check note that 
$$
\left(\begin{array}{rrr}
1&3&0\\1&-2&1\\2&1&1
\end{array}\right)\  \begin{pmatrix}\frac{11}5\\ \frac35\\ 0\end{pmatrix}=\begin{pmatrix}4\\ 1\\ 5\end{pmatrix}
\mbox{ and }
\left(\begin{array}{rrr}
1&3&0\\1&-2&1\\2&1&1
\end{array}\right)\ \begin{pmatrix}-\frac35\\\frac15\\1\end{pmatrix}=\begin{pmatrix}0\\0\\0\end{pmatrix}\, .
$$


\item

\begin{enumerate}
\item The augmented matrix 
$$
\left(\begin{array}{rrrr|r}
1&0&-1&2&-1\\[1mm]
1&1&1&-1&2\\[1mm]
0&-1&-2&3&-3\\[1mm]
5&2&-1&4&1
\end{array}\right)
$$
encodes the system of equations. 
\item 
{\it Again, write out the row operations as an additional exercise.}\\
The above augmented matrix is row equivalent to  
$$
%\sim
\left(\begin{array}{rrrr|r}
1&0&-1&2&-1\\[1mm]
0&1&2&-3&3\\[1mm]
0&-1&-2&3&-3\\[1mm]
0&2&4&-6&6
\end{array}\right)
\sim
\left(\begin{array}{rrrr|r}
1&0&-1&2&-1\\[1mm]
0&1&2&-3&3\\[1mm]
0&0&0&0&0\\[1mm]
0&0&0&0&0
\end{array}\right)
$$
which is in reduced row echelon form.

\item
Solution set is 
$$
\left\{X=\begin{pmatrix}-1\\3 \\ 0\\0\end{pmatrix}
+\mu_1 \begin{pmatrix} 1 \\-2\\1\\0\end{pmatrix}
+\mu_2 \begin{pmatrix}-2\\3\\0\\1\end{pmatrix}
\colon \mu_1,\mu_2 \in \mathbb{R}
\right\}\, .
$$

\item
The vector $X_0=\begin{pmatrix}-1\\3 \\ 0\\0\end{pmatrix}$ is {\it a } particular solution and the vectors 
$$Y_1=\begin{pmatrix} 1 \\-2\\1\\0\end{pmatrix} 
{\rm ~and~ } 
Y_2= \begin{pmatrix}-2\\3\\0\\1\end{pmatrix}$$ 
are homogeneous solutions.
They obey
$$
MX=V\, ,\qquad M Y_1=0=MY_2\, .
$$
where 
$$M=\left(\begin{array}{rrrr}
1&0&-1&2\\
1&1&1&-1\\
0&-1&-2&3\\
5&2&-1&4
\end{array}\right) {\rm ~and~}
V=\begin{pmatrix}-1\\2\\-3\\1\end{pmatrix}.$$ 

\item This amounts to  explicitly performing the matrix manipulations 
$$MX-V,~ MY_1, {\rm ~and~} MY_2$$
to verify that they are all zero vectors.

\end{enumerate}

\item 
{\it As usual, be sure to write out the row operations above the $\sim$'s so your work can be easily checked.}
$$
\phantom{\sim}
\left(
\begin{array}{rrrr|rrrr}
1&2&3&4&1&0&0&0\\
2&4&7&11&0&1&0&0\\
3&7&14&25&0&0&1&0\\
4&11&25&50&0&0&0&1
\end{array}\right)
$$
$$
\sim
\left(
\begin{array}{rrrr|rrrr}
1&2&3&4&1&0&0&0\\
0&0&1&3&-2&1&0&0\\
0&1&5&13&-3&0&1&0\\
0&3&13&34&-4&0&0&1
\end{array}\right)
$$
$$
\sim
\left(
\begin{array}{rrrr|rrrr}
1&0&-7&-22&7&0&-2&0\\
0&1&5&13&-3&0&1&0\\
0&0&1&3&-2&1&0&0\\
0&0&-2&-5&5&0&-3&1
\end{array}\right)
$$
$$
\sim
\left(
\begin{array}{rrrr|rrrr}
1&0&0&-1&-7&7&-2&0\\
0&1&0&-2&7&-5&1&0\\
0&0&1&3&-2&1&0&0\\
0&0&0&1&1&2&-3&1
\end{array}\right)
$$
$$
\sim
\left(
\begin{array}{rrrr|rrrr}
1&0&0&0&-6&9&-5&1\\
0&1&0&0&9&-1&-5&2\\
0&0&1&0&-5&-5&9&-3\\
0&0&0&1&1&2&-3&1
\end{array}\right)\, .
$$
Check
$$
\begin{pmatrix}
1&2&3&4\\2&4&7&11\\3&7&14&25\\4&11&25&50
\end{pmatrix}
\begin{pmatrix}
-6&9&-5&1\\9&-1&-5&2\\-5&-5&9&-3\\1&2&-3&1
\end{pmatrix}
=
\begin{pmatrix}
1&0&0&0\\0&1&0&0\\0&0&1&0\\0&0&0&1
\end{pmatrix}\, .
$$

\item
$$
M^T M^{-1}=
\begin{pmatrix}2&3\\1&-1\end{pmatrix}\begin{pmatrix}\frac15&\frac15\\[1mm]\frac35&-\frac25\end{pmatrix}
=\begin{pmatrix}\frac{11}5&-\frac45\\-\frac25&\frac35\end{pmatrix}\, .
$$
Since $M^TM^{-1}\neq I$, it follows $M^T\neq M$ so $M$ is {\it not} symmetric.
Finally
$$
{\rm tr} f(M)^T= {\rm tr} f(M) = {\rm tr}(M^2-I)={\rm tr}\begin{pmatrix}2&1\\3&-1\end{pmatrix}\begin{pmatrix}2&1\\3&-1\end{pmatrix}-{\rm tr} I
$$
$$
=(2\cdot 2+1\cdot 3)+(3\cdot 1+(-1)\cdot(-1))-2=9\, .
$$

\item First $$X\dotprod (MX)=X^T M X = \begin{pmatrix}x & y\end{pmatrix}
\begin{pmatrix}\cos\theta &\sin\theta \\ -\sin\theta & \cos\theta\end{pmatrix}
\begin{pmatrix}x \\ y\end{pmatrix}$$
$$
\hspace{2cm}
= \begin{pmatrix}x & y\end{pmatrix}\begin{pmatrix}x \cos\theta + y\sin\theta \\ -x\sin\theta + y\cos\theta\end{pmatrix}
=(x^2+y^2)\cos\theta\, .
$$
Now $||X||=\sqrt{X\dotprod X}=\sqrt{x^2 + y^2}$ and 
$
(MX)\dotprod (MX)= X M^T M X
$. But
$$
M^T M = \begin{pmatrix}\cos\theta &-\sin\theta \\ \sin\theta & \cos\theta\end{pmatrix}
\begin{pmatrix}\cos\theta &\sin\theta \\ -\sin\theta & \cos\theta\end{pmatrix}$$ $$=
\begin{pmatrix}\cos^2\theta +\sin^2\theta& 0 \\ 0 & \cos^2\theta +\sin^2\theta\end{pmatrix}=I\, .
$$
Hence $||MX||=||X||=\sqrt{x^2+y^2}$. Thus the cosine of the angle between $X$ and $MX$ is given by
$$
\frac{X\dotprod (MX)}{||X|| \ ||MX||}= \frac{(x^2+y^2)\cos\theta}{\sqrt{x^2+y^2}\, \sqrt{x^2+y^2}} = \cos \theta\, .
$$
In other words, the angle is $\theta$ OR $-\theta$. You should draw two pictures, one where the angle between
$X$ and $MX$ is $\theta$, the other where it is $-\theta$. 


For Cauchy--Schwartz, $\frac{|X\dotprod (MX)|}{||X|| \ ||MX||}=|\cos\theta|=1$ when $\theta=0,\pi$. 
For the triangle equality $MX = X$ achieves $||X+MX||=||X||+||MX||$, which requires $\theta=0$. 

\item This is a block matrix problem. Notice the that matrix $M$ is really just $M=
\begin{pmatrix}
I&I\\0&I
\end{pmatrix}
$, where $I$ and $0$ are the $3\times3$ identity zero matrices, respectively. But
$$
M^2=\begin{pmatrix}
I&I\\0&I
\end{pmatrix}
\begin{pmatrix}
I&I\\0&I
\end{pmatrix}
=
\begin{pmatrix}
I&2I\\0&I
\end{pmatrix}
$$
and 
$$
M^3=\begin{pmatrix}
I&I\\0&I
\end{pmatrix}
\begin{pmatrix}
I&2I\\0&I
\end{pmatrix}
=
\begin{pmatrix}
I&3I\\0&I
\end{pmatrix}
$$
so, $M^k=\begin{pmatrix}
I&kI\\0&I
\end{pmatrix}$, or explicitly
$$
M^k=
\begin{pmatrix}
1&0&0&k&0&0\\
0&1&0&0&k&0\\
0&0&1&0&0&k\\
0&0&0&1&0&0\\
0&0&0&0&1&0\\
0&0&0&0&0&1
\end{pmatrix}\, .
$$


\item We can call a function $f\colon V\longrightarrow W$ {\it linear} if the sets $V$ and $W$ are vector spaces
and $f$ obeys
$$
f(\alpha u + \beta v)=\alpha f(u)+\beta f(v)\, ,
$$
for all $u,v\in V$ and $\alpha,\beta\in {\mathbb R}$.

Now, integration is a linear transformation from 
the space $V$ of all integrable functions (don't be confused between the definition of a linear function above, 
and integrable functions $f(x)$ which here are the vectors in $V$) to the real numbers ${\mathbb R}$, because 
$\int_{-\infty}^\infty (\alpha f(x) +\beta g(x))dx = \alpha \int_{-\infty}^\infty f(x) dx + \beta \int_{-\infty}^\infty g(x) dx$.

\item The four main ingredients are
(i) a set $V$ of vectors, (ii) a number field~$K$ (usually $K={\mathbb R})$, (iii) a rule for adding vectors (vector addition) and (iv) a way to multiply vectors by a number to produce a new vector (scalar multiplication). 
There are, of course, \hyperref[vectorspace]{ten rules} that these four ingredients must obey.

\begin{enumerate}
\item This is not a vector space. Notice that distributivity of scalar multiplication requires
$2 u = (1+1) u = u + u$ for any vector $u$ but
$$
2\cdot \begin{pmatrix} a& b\\ c& d\end{pmatrix} =  \begin{pmatrix} 2a& b\\ 2c& d\end{pmatrix}
$$
which does {\it not} equal
$$
\begin{pmatrix} a& b\\ c& d\end{pmatrix}+\begin{pmatrix} a& b\\ c& d\end{pmatrix}=
\begin{pmatrix} 2a& 2b\\ 2c& 2d\end{pmatrix}\, .
$$ 
This could be repaired by taking $$ k\cdot \begin{pmatrix} a& b\\ c& d\end{pmatrix}=
\begin{pmatrix} ka& kb\\ kc& kd\end{pmatrix}\, .$$
\item This is a vector space. {\it Although, the question does not ask you to, it is a useful exercise
to verify that all \hyperref[vectorspace]{ten vector space rules} are satisfied.}
\item This is not a vector space for many reasons. An easy one is that $(1,-1,0)$ and $(-1,1,0)$
are both in the space, but their sum $(0,0,0)$ is not ({\it i.e.}, additive closure fails).
The easiest way to repair this would be to drop the requirement that there be at least one entry equaling 1.
 
 \end{enumerate}
 
 \item 
 (i) Thanks to multiplicative closure, if $u\in U$, so is $(-1)\cdot u$. But $(-1) \cdot u + u = (-1)\cdot u + 1\cdot u
 = (-1+1)\cdot u= 0.u = 0$ (at each step in this chain of equalities we have used the fact that $V$ is a vector space
 and therefore can use its vector space rules). In particular, this means that the zero vector of $V$ is in $U$ and  is its
 zero vector also.  (ii) Also, in $V$, for each $u$ there is an element $-u$ such that $u+(-u)=0$. But by additive 
 close, $(-u)$ must also be in $U$, thus every $u\in U$ has an additive inverse.
 
 
 \begin{enumerate}
 \item This is a vector space. First we check additive closure: let $\begin{pmatrix}x \\ y\\0\end{pmatrix}$ and $\begin{pmatrix}z \\ w\\0\end{pmatrix}$
 be arbitrary vectors in $U$. But since $\begin{pmatrix}x \\ y\\0\end{pmatrix} + \begin{pmatrix}z \\ w\\0\end{pmatrix}
 = \begin{pmatrix}x+z \\ y+w\\0\end{pmatrix}$, so is their sum (because vectors in $U$ are those whose third component vanishes).  Multiplicative closure is similar: for any $\alpha\in {\mathbb R}$, $\alpha \begin{pmatrix}x \\ y\\0\end{pmatrix}= \begin{pmatrix}\alpha x \\ \alpha y\\0\end{pmatrix}$, which also has no third component, so is in $U$.
 
 \item This is not a vector space for various reasons. A simple one is that $u=\begin{pmatrix}1\\0\\z\end{pmatrix}$
 is in~$U$ but the vector $u+u=\begin{pmatrix}2\\0\\2z\end{pmatrix}$ is not in~$U$ (it has a 2 in the first component, 
 but vectors in~$U$ always have a 1 there).
 \end{enumerate}
 

\item
$$
\begin{pmatrix}
1&1&-1&2\\
1&3&2&2\\
-1&-3&-4&6\\
0&4&7&-2
\end{pmatrix}
=
\begin{pmatrix}
1&0&0&0\\
1&1&0&0\\
-1&0&1&0\\
0&0&0&1
\end{pmatrix}
\begin{pmatrix}
1&1&-1&2\\
0&2&3&0\\
0&-2&-5&8\\
0&4&7&-2
\end{pmatrix}
$$
$$
=
\begin{pmatrix}
1&0&0&0\\
1&1&0&0\\
-1&-1&1&0\\
0&2&0&1
\end{pmatrix}
\begin{pmatrix}
1&1&-1&2\\
0&2&3&0\\
0&0&-2&8\\
0&0&1&-2
\end{pmatrix}
$$ $$=
\begin{pmatrix}
1&0&0&0\\
1&1&0&0\\
-1&-1&1&0\\
0&2&-\frac12&1
\end{pmatrix}
\begin{pmatrix}
1&1&-1&2\\
0&2&3&0\\
0&0&-2&8\\
0&0&0&2
\end{pmatrix}\, .
$$
To solve $MX=V$ using $M=LU$ we first solve $LW=V$ whose augmented matrix reads
$$
\left(
\begin{array}{cccc|c}
1&0&0&0&7\\
1&1&0&0&6\\
-1&-1&1&0&12\\
0&2&-\frac12&1&-7
\end{array}\right)
\sim 
\left(
\begin{array}{cccc|c}
1&0&0&0&7\\
0&1&0&0&-1\\
0&0&1&0&18\\
0&2&-\frac12&1&-7
\end{array}\right)$$ $$\sim 
\left(
\begin{array}{cccc|c}
1&0&0&0&7\\
0&1&0&0&-1\\
0&0&1&0&18\\
0&0&0&1&4
\end{array}\right)\, ,
$$
from which we can read off $W$.
Now we compute $X$ by solving $UX=W$ with the augmented matrix
$$
\left(
\begin{array}{cccc|c}
1&1&-1&2&7\\
0&2&3&0&-1\\
0&0&-2&8&18\\
0&0&0&2&4
\end{array}\right)
\sim
\left(
\begin{array}{cccc|c}
1&1&-1&2&7\\
0&2&3&0&-1\\
0&0&-2&0&2\\
0&0&0&1&2
\end{array}\right)
$$
$$
\sim
\left(
\begin{array}{cccc|c}
1&1&-1&2&7\\
0&2&0&0&2\\
0&0&1&0&-1\\
0&0&0&1&2
\end{array}\right)
\sim
\left(
\begin{array}{cccc|c}
1&0&0&0&1\\
0&1&0&0&1\\
0&0&1&0&-1\\
0&0&0&1&2
\end{array}\right).
$$
So $x=1$, $y=1$, $z=-1$ and $w=2$.

\end{enumerate}

\newpage
