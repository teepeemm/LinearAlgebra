\chapter{\vectorSpacesTitle}
\label{vectorSpaces}

%Thus far we have thought of vectors as lists of numbers% in $\mathbb{R}^n$.  As it turns out, The notion of a vector applies to a much more general class of structures than this.
As suggested at the end of chapter~\ref{vectorsinspace}, the vector spaces $\mathbb{R}^n$ are not the only vector spaces. 
We now give a general definition that  includes $\Re^n$ for all values of $n$, and $\mathbb{R}^{S}$ for all sets $S$, and more.
%The main idea is to  define vectors based on their most important properties.  
%Vectors in $\mathbb{R}^n$ will fit our definition, but so will many other extremely useful notions of vectors. 
This mathematical structure
is applicable to a wide range of real-world problems and allows for tremendous economy of thought; the idea of a basis for a vector space will drive home the main idea of vector spaces; they are sets with very simple structure. 


The two key properties of vectors are that they can be added together and multiplied by scalars. 
Thus, before giving a rigorous definition of vector spaces, we restate the main idea.\\

\begin{center} \shabox{ 
 A vector space is a set that is closed under addition and scalar~multiplication.}
\end{center}



\begin{definition} A {\bf vector space}\index{Vector space}\label{vectorspace} $(V,+,.\, ,{\mathbb R})$ is a set $V$ with two operations $+$ and~$\cdot$ satisfying the following properties for all $u, v \in V$ and $c, d \in \mathbb{R}$:

\begin{itemize}

\item[(+i)] (Additive Closure)\index{Closure!additive} $u+v \in V$.  {\it Adding two vectors gives a vector.}

\item[(+ii)] (Additive Commutativity) $u+v=v+u$.  {\it Order of addition does not matter.}

\item[(+iii)] (Additive Associativity) $(u+v)+w = u+(v+w)$.  {\it Order of adding many vectors does not matter.}

\item[(+iv)] (Zero) There is a special vector $0_V \in V$ such that $u+0_V = u$ for all $u$ in $V$.

\item[(+v)] (Additive Inverse) For every $u \in V$ there exists $w \in V$ such that $u+w=0_V$.

\item[($\cdot$ i)] (Multiplicative Closure)\index{Closure!multiplicative} $c\cdot v \in V$.  {\it Scalar times a vector is a vector.}

\item[($\cdot$ ii)] (Distributivity) $(c+d) \cdot v= c\cdot v + d\cdot v$.  {\it Scalar multiplication distributes over addition of scalars.}

\item[($\cdot$ iii)] (Distributivity) $c\cdot (u+v)= c\cdot u + c\cdot v$.  {\it Scalar multiplication distributes over addition of vectors.}

\item[($\cdot$ iv)] (Associativity) $ (cd)\cdot v = c \cdot (d \cdot v)$. 

\item[($\cdot$ v)] (Unity) $1\cdot v = v$ for all $v \in V$.
\end{itemize}
\end{definition}

\Videoscriptlink{vector_spaces_definition_example.mp4}{Examples of each rule}{scripts_vector_spaces_definition_example}

\begin{remark}
Rather than writing $(V,+,.\, ,{\mathbb R})$, we will often say ``let $V$ be a vector space over ${\mathbb R}$''. If it is obvious that the numbers used are real numbers, then ``let $V$ be a vector space'' suffices.
Also, don't confuse the scalar product $\cdot$ with the dot product~$\dotprod$.  The scalar product is a function that takes as its two inputs one number and one vector  and returns a vector as its output.  This can be written 
$$\cdot \colon \mathbb{R}\times V \rightarrow V\, .$$ 
Similarly
$$
+:V\times V \rightarrow V\, .
$$
On the other hand, the dot product takes two vectors and returns a number.  Succinctly: $\dotprod \colon V\times V \rightarrow \Re$.
Once the properties of a vector space have been verified, we'll just write scalar multiplication with juxtaposition $cv=c\cdot v$, though, to keep our notation efficient. 
\end{remark}


\section{Examples of Vector Spaces}
%\begin{remark}
%It isn't hard to devise strange rules for addition or scalar multiplication that break some or all of the rules listed above.
%\end{remark}

One can  find many interesting vector spaces, such as the following:
\Videoscriptlink{vector_spaces_example.mp4}{Example of a vector space}{scripts_vector_spaces_example}

\begin{example}
\[ \mathbb{R}^\mathbb{N} = \{f \mid f \colon \mathbb{N} \rightarrow \Re \} \]
Here the vector space is the set of functions that take in a natural number~$n$ and return a real number.  The addition is just addition of functions: $(f_1 + f_2)(n) = f_1(n) + f_2(n)$.  Scalar multiplication is just as simple: $c \cdot f(n) = cf(n)$.

%We can think of these functions as infinite column vectors: $f(0)$ is the first entry, $f(1)$ is the second entry, and so on.  Then for example the function $f(n) = n^3$ would look like this:

%\[
%f(n) = \colvec{0\\1\\8\\27\\ \vdots \\ n^3 \\ \vdots}
%\]
%Alternatively, $V$ is the space of sequences: $f = \{f_1, f_2, \ldots, f_n, \ldots \}$.

We can think of these functions as infinitely large ordered lists of numbers: \(f(1)=1^3=1\) is the first component, \(f(2)=2^3=8\) is the second, and so on. Then for example the function \(f(n)=n^3\) would look like this:
\[
f=\ccolvec{1\\ 8\\ 27\\ \vdots\\ n^3\\ \vdots }.
\]
Thinking this way, \(\Re^\mathbb{N}\) is the space of all infinite sequences. 
Because we can not write a list infinitely long (without infinite time and ink), one can not define an element of this space explicitly; definitions that are implicit, as above, or algebraic as in $f(n)=n^3$ (for all $n \in \mathbb{N}$) suffice.

Let's check some axioms.

\begin{itemize}
\item[(+i)] (Additive Closure) $(f_1 + f_2)(n)=f_1(n) +f_2(n)$ is indeed a function 
$\mathbb{N} \rightarrow \Re$, since the sum of two real numbers is a real number.

\item[(+iv)] (Zero) We need to propose a zero vector.  The constant zero function $g(n) = 0$ works because then $f(n) + g(n) = f(n) + 0 = f(n)$.
\end{itemize}
The other axioms should also be checked.  This can be done using  properties of the real numbers.
\Reading{VectorSpaces}{1}
\end{example}

\begin{example} The space of functions of one real variable.\\
\[ \mathbb{R}^\mathbb{R} = \{f \mid f \colon \Re \to \Re \} \]
The addition is point-wise $$(f+g)(x)=f(x)+g(x)\, ,$$ as is scalar multiplication $$c\cdot f(x)=cf(x)\, .$$  
To check that $\Re^\Re$ is a vector space use the properties of addition of functions and scalar multiplication of functions as in the previous example. 


We can not write out an explicit definition for one of these functions either, there are not only infinitely many components, but even infinitely many components between any two components!  
You are familiar with algebraic definitions like $f(x)=e^{x^2-x+5}$. However, most vectors in this vector space can not be defined algebraically. For example, the nowhere continuous function 
\begin{displaymath}
   f(x) = \left\{
     \begin{array}{lr}
       1\, , & x \in \mathbb{Q}\\[2mm]
       0\, , &  x \notin \mathbb{Q}
     \end{array}
   \right. .
\end{displaymath} 
\end{example}

\begin{example} $\Re^{ \{*, \star, \# \}} = \{ f : \{*, \star, \# \} \to \Re \}$. Again, the properties of addition and scalar multiplication of functions show that this is a vector space.
\end{example}

You can probably figure out how to show that $\Re^S$ is vector space for any set $S$.  
This might lead you to guess that all vector spaces are of the form $\Re^S$ for some set $S$. The following is a counterexample. 

\begin{example}
Another very important example of a vector space is the space of all differentiable functions: 
\[
\left\{ f \colon \Re\rightarrow \Re \, \Big|\, \frac{d}{dx}f \text{ exists} \right\}.
\]

From calculus, we know that the sum of any two differentiable functions is differentiable, since the derivative distributes over addition.  A scalar multiple of a function is also differentiable, since the derivative commutes with scalar multiplication ($\frac{d}{d x}(cf)=c\frac{d}{dx}f$).  The zero function is just the function such that $0(x)=0$ for every $x$.  The rest of the vector space properties are inherited from addition and scalar multiplication in $\Re$.
\end{example}

Similarly, the set of functions with at least $k$ derivatives is always a vector space, as is the space of functions with infinitely many derivatives. 
None of these examples can be written as $\Re^S$ for some set $S$.
Despite our emphasis on such examples, it is also not true that all vector spaces consist of functions. Examples are somewhat esoteric, so we omit them.

Another important class of examples is vector spaces that live inside $\Re^n$ but are not themselves $\Re^n$. 

\begin{example} (Solution set to a homogeneous linear equation.)\\
Let 
\[ M = \begin{pmatrix}
      1 & 1 &1 \\
      2&2&2 \\
      3&3&3
    \end{pmatrix}.\]
    The solution set to the homogeneous equation $Mx=0$ is 
$$\left\{ c_1\colvec{-1\\1\\0} + c_2 \colvec{-1\\0\\1} \middle\vert c_1,c_2\in \Re \right\}.$$
    This set is not equal to $\Re^3$ since it does not contain, for example,  $\colvec{1\\0\\0}$. 
The sum of any two solutions is a solution, for example 
$$
    \left[ 2\colvec{-1\\1\\0} + 3 \colvec{-1\\0\\1} \right] 
+ \left [ 7\colvec{-1\\1\\0} + 5 \colvec{-1\\0\\1} \right]
=
 9\colvec{-1\\1\\0} + 8 \colvec{-1\\0\\1} 
$$
and any scalar multiple of a solution is a solution
$$
4\left[ 5\colvec{-1\\1\\0} - 3 \colvec{-1\\0\\1} \right]
=      20\colvec{-1\\1\\0} - 12 \colvec{-1\\0\\1} . 
$$
This example is called a {\it subspace} because it gives a vector space inside another vector space. See chapter~\ref{subspacesspanning}
for details. Indeed, because it is determined by the linear map given by the matrix $M$, it is called $\ker M$, or in words, the {\it kernel} of $M$,
for this see chapter~\ref{kernelrank}. 
\end{example}

Similarly, the solution set to any homogeneous linear equation is a vector space:
Additive and multiplicative closure follow from the following statement, made using linearity of matrix multiplication:
$${\rm If}~Mx_1=0 ~\mbox{and}~Mx_2=0~ \mbox{then} ~M(c_1x_1 + c_2x_2)=c_1Mx_1+c_2Mx_2=0+0=0.$$ 
A powerful result, called the subspace theorem (see chapter~\ref{subspacesspanning}) guarantees, based on the closure properties alone, that homogeneous
solution sets are vector spaces.

More generally, if $V$ is any vector space, then any hyperplane through the origin of $V$ is a vector space. 

\begin{example} Consider the functions $f(x)=e^x$ and $g(x)=e^{2x}$ in $\Re^\Re$. By taking combinations of these two vectors we can form the plane $\{ c_1 f+ c_2 g | c_1,c_2 \in \Re\}$
inside of $\Re^\Re$. This is a vector space; 
some examples of vectors in it are 
$4e^x-31e^{2x},~\pi e^{2x}-4e^x$ and $\frac12e^{2x}$. 
\end{example}

A hyperplane which does not contain the origin cannot be a vector space because it fails condition (+iv).

It is also possible to build new vector spaces from old ones using the product of sets. Remember that if $V$ and $W$ are sets, then
their product is the new set
$$
V\times W = \{(v,w)|v\in V, w\in W\}\, ,
$$
or in words, all ordered pairs of elements from $V$ and $W$.
In fact $V\times W$ is a vector space if $V$ and $W$ are. We have actually been using this fact already:

\begin{example}
The real numbers~${\mathbb R}$ form a vector space (over ${\mathbb R}$). The new vector space
$${\mathbb R}\times {\mathbb R}=\{(x,y)|x\in{\mathbb R}, y\in {\mathbb R}\}$$
has addition and scalar multiplication defined by
$$
(x,y)+(x',y')=(x+x',y+y')\, \mbox{ and } c.(x,y)=(cx,cy)\, .
$$
Of course, this is just the vector space ${\mathbb R}^2={\mathbb R}^{\{1,2\}}$. 
\end{example}

\subsection{Non-Examples} 
The solution set to a linear non-homogeneous equation is not a vector space because it does not contain the zero vector and therefore fails (iv).

\begin{example} 
The solution set to 
\[  \begin{pmatrix}
      1 & 1 \\
      0 & 0 
    \end{pmatrix} \colvec{x\\y} = \colvec{1\\0} \]
is  $\left\{ \colvec{1\\0} + c \colvec{-1\\1} \Big|\, c \in \Re \right\}$.
The vector $\colvec{0\\0}$ is not in this set.
\end{example}
Do notice that if just one of the vector space rules is broken, the example is not a vector space.

Most sets of $n$-vectors are not vector spaces. 
\begin{example} 
$P:=\left \{ \colvec{a\\b} \Big| \,a,b \geq 0 \right\}$ is not a vector space because the set fails ($\cdot$i) since 
$\colvec{1\\1}\in P$ but $-2\colvec{1\\1} =\colvec{-2\\-2} \notin P$.
\end{example}


Sets of functions other than those of the form $\Re^S$ should be carefully checked for compliance with the definition of a vector space.


\begin{example}
The set of all functions which are nowhere zero 
\[\left\{ f \colon \Re\rightarrow \Re \mid f(x)\neq 0 {\rm ~for~any}~x\in\Re \right\}\, ,\]
does not form a vector space because it does not satisfy (+i). The functions $f(x)=x^2+1$ and $g(x)= -5$ are in the set, but their sum $(f+g)(x)=x^2-4=(x+2)(x-2)$ is not since $(f+g)(2)=0$.
\end{example}


\section{Other Fields} \label{otherfields}
Above, we defined vector spaces over the real numbers.  One can actually define vector spaces over any \emph{field}.
This is referred to as choosing a different {\it base field}\index{Base field}.
  A field is a collection of ``numbers'' satisfying  properties which are listed in appendix~\ref{fields}.
An example of a field is the complex numbers, 
\[
\mathbb{C}= \left\{x+iy \mid i^2=-1, x,y\in \Re \right\}.
\]

\begin{example}
In quantum physics, vector spaces over $\mathbb{C}$ describe all possible states a physical system %of particles 
can have.  
For example,
\[
V= \left\{ \colvec{\lambda \\ \mu} \mid \lambda, \mu \in \mathbb{C}\right\}
\]
is the set of possible states for an electron's spin. The vectors \scalebox{.9}{$\colvec{1 \\ 0}$}  and~\scalebox{.9}{$\colvec{0 \\ 1}$} describe, respectively,  an  electron with spin ``up'' and ``down'' along a given direction.  
Other vectors, like \scalebox{.9}{$\colvec{i \\ -i}$} are permissible, since the base field is the complex numbers. Such states represent a mixture of spin up and spin down for the given direction (a rather counterintuitive yet experimentally verifiable concept), but a given spin in some other direction.
\end{example}

Complex numbers are very useful because of a special property that they enjoy: every polynomial over the complex numbers factors into a product of linear polynomials.  For example, the polynomial $$x^2+1$$ doesn't factor over  real numbers, but over complex numbers it factors into $$(x+i)(x-i)\, .$$ In other words, there are {\it two} solutions to $$x^2=-1,$$
$x=i$ and $x=-i$.
 This property  has far-reaching consequences: often in mathematics problems that are very difficult using only real numbers become relatively simple when working over the complex numbers.  This phenomenon occurs when diagonalizing matrices, see chapter~\ref{sec:diagonalization}.

The rational numbers $\mathbb{Q}$ are also a field. This  field is important in computer algebra: a real number given by an infinite string of numbers after the decimal point can't be stored by a computer.  So instead rational approximations are used.  Since the rationals are a field, the mathematics of vector spaces still apply to this special case.

Another very useful field is bits 
$$
B_2={\mathbb Z}_2=\{0,1\}\, ,
$$
with the addition and multiplication rules
$$
\begin{array}{c|cc}
+&0&1\\\hline
0&0&1\\
1&1&0
\end{array}\qquad
\begin{array}{c|cc}
\times&0&1\\\hline
0&0&0\\
1&0&1
\end{array}
$$
These rules can be summarized by the relation $2=0$. For bits, it follows that $-1=1$!
%In this class, we will work mainly over the real numbers and the complex numbers, and occasionally work over $\mathbb{Z}_2 = \{0, 1\}$ where $1 + 1 = 0$. 
%For more on fields in general, see \hyperref[fields]{Appendix~\ref*{fields}}; however 

The theory of fields is typically covered in a class on abstract algebra or Galois theory\index{Galois}.


%\section*{References}
%
%Hefferon, Chapter One, Section I.1
%\\
%Beezer, Chapter VS, Section VS
%\\
%Wikipedia:
%\begin{itemize}
%\item \href{http://en.wikipedia.org/wiki/Vector_space}{Vector Space}
%\item \href{http://en.wikipedia.org/wiki/Field_(mathematics)}{Field}
%\item \href{http://en.wikipedia.org/wiki/Spin_1/2}{Spin $\frac{1}{2}$}
%\item \href{http://en.wikipedia.org/wiki/Spin_1/2}{Galois Theory}
%
%\end{itemize}

\section{Review Problems}

{\bf Webwork:} 
\begin{tabular}{|c|c|}
\hline
Reading problems &
\hwrref{VectorSpaces}{1}\\
Addition and inverse& \hwref{VectorSpaces}{2}\\
\hline
\end{tabular}

\input{\vectorSpacesPath/problems}


\newpage
