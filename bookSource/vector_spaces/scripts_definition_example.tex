
\subsection*{Examples of Each Rule}

%%%Insert this to get the typewriter font so it looks like a real movie script
{\ttfamily
\fontdimen2\font=0.4em
\fontdimen3\font=0.2em
\fontdimen4\font=0.1em
\fontdimen7\font=0.1em
\hyphenchar\font=`\-


%%%%put a hypertarget around the opening bit of text
\hypertarget{scripts_vector_spaces_definition_example}{Lets show that ${\mathbb R}^2$} is a vector space.
To do this (unless we invent some clever tricks) we will have to check all parts of the definition. Its worth doing this once, so here we go:

Before we start, remember that for ${\mathbb R}^2$ we define
vector addition and scalar multiplication component-wise.

\begin{enumerate}
\item[(+i)] Additive closure: We need to make sure that
when we add $\begin{pmatrix}x_1\\x_2\end{pmatrix}$
and $\begin{pmatrix}y_1\\y_2\end{pmatrix}$ that we do not 
get something outside the original vector space ${\mathbb R}^2$. This just relies on the underlying structure of real numbers whose sums are again real numbers so, using our component-wise addition law we have
$$
\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\begin{pmatrix}y_1\\y_2\end{pmatrix}
:=
\begin{pmatrix}x_1+x_2\\y_1+y_2\end{pmatrix}\in {\mathbb R}^2\, .
$$
\item[(+ii)] Additive commutativity: We want to check that when we add any two vectors we can do so in either order, {\it i.e.} 
$$
\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\begin{pmatrix}y_1\\y_2\end{pmatrix}
\stackrel?=
\begin{pmatrix}y_1\\y_2\end{pmatrix}+
\begin{pmatrix}x_1\\x_2\end{pmatrix}\, .$$

This again relies on the underlying real numbers which for any $x,y\in {\mathbb R}$ obey 
$$x+y=y+x\, .$$
This fact underlies the middle step of the following computation
$$
\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\begin{pmatrix}y_1\\y_2\end{pmatrix}
=
\begin{pmatrix}x_1+y_1\\x_2+y_2\end{pmatrix}
=
\begin{pmatrix}y_1+x_1\\y_2+x_2\end{pmatrix}
=
\begin{pmatrix}y_1\\y_2\end{pmatrix}+
\begin{pmatrix}x_1\\x_2\end{pmatrix}\, ,$$
which demonstrates what we wished to show.
\item[(+iii)] Additive Associativity:
This shows that we needn't specify with parentheses which 
order we intend to add triples of vectors because their sums 
will agree for either choice. What we have to check is
$$
\left(\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\begin{pmatrix}y_1\\y_2\end{pmatrix}\right)+
\begin{pmatrix}z_1\\z_2\end{pmatrix}
\stackrel?=
\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\left(\begin{pmatrix}y_1\\y_2\end{pmatrix}+
\begin{pmatrix}z_1\\z_2\end{pmatrix}\right)\, .$$
Again this relies on the underlying associativity of real numbers:
$$
(x+y)+z=x+(y+z)\, .
$$
The computation required is
$$
\left(\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\begin{pmatrix}y_1\\y_2\end{pmatrix}\right)+
\begin{pmatrix}z_1\\z_2\end{pmatrix}
=
\begin{pmatrix}x_1+y_1\\x_2+y_2\end{pmatrix}+
\begin{pmatrix}z_1\\z_2\end{pmatrix}
=
\begin{pmatrix}(x_1+y_1)+z_1\\(x_2+y_2)+z_2\end{pmatrix}
$$ $$
=
\begin{pmatrix}x_1+(y_1+z_1)\\x_2+(y_2+z_2)\end{pmatrix}
=
\begin{pmatrix}x_1\\ y_1\end{pmatrix}+
\begin{pmatrix}y_1+z_1\\y_2+z_2\end{pmatrix}=
\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\left(\begin{pmatrix}y_1\\y_2\end{pmatrix}+
\begin{pmatrix}z_1\\z_2\end{pmatrix}\right)\, .$$
\item[(iv)] Zero: There needs to exist a vector $\vec 0$ that works the way we would 
expect zero to behave, {\it i.e.}
$$
\begin{pmatrix}x_1\\y_1\end{pmatrix}+\vec 0=\begin{pmatrix}x_1\\y_1\end{pmatrix}\, .
$$
It is easy to find, the answer is
$$
\vec 0 = \begin{pmatrix}0\\0\end{pmatrix}\, .
$$
You can easily  check that when this vector is added to any vector, the result is unchanged.
\item[(+v)] Additive Inverse: We need to check that when we have 
$\begin{pmatrix}x_1\\x_2\end{pmatrix}$, there is another vector 
that can be added to it so the sum is $\vec 0$. (Note that it is important to first figure out what $\vec 0$ is here!) The answer for the additive inverse of $\begin{pmatrix}x_1\\x_2\end{pmatrix}$ is
$
\begin{pmatrix}-x_1\\-x_2\end{pmatrix}
$
because
$$
\begin{pmatrix}x_1\\x_2\end{pmatrix}+
\begin{pmatrix}-x_1\\-x_2\end{pmatrix}
=\begin{pmatrix}x_1-x_1\\x_2-x_2\end{pmatrix}=
\begin{pmatrix}0\\0\end{pmatrix}=\vec 0\, .
$$
\end{enumerate}
We are half-way done, now we need to consider the rules for scalar multiplication. Notice, that we multiply vectors by scalars
({\it i.e.} numbers) but do NOT multiply a vectors by  vectors.

\begin{enumerate}
\item[($\cdot$i)] Multiplicative closure: Again, we are checking that 
an operation does not produce vectors outside the vector space. For a scalar $a\in{\mathbb R}$, we require that $a
\begin{pmatrix}x_1\\x_2\end{pmatrix}$ lies in ${\mathbb R}^2$.
First we compute using our component-wise rule for scalars times vectors:
$$
a
\begin{pmatrix}x_1\\x_2\end{pmatrix}=
\begin{pmatrix}ax_1\\ax_2\end{pmatrix}\, .
$$
Since products of real numbers $a x_1$ and $a x_2$ are again real numbers we see this is indeed inside ${\mathbb R}^2$.
\item[($\cdot$ii)] Multiplicative distributivity: The equation we need to check is
$$
(a+b)
\begin{pmatrix}x_1\\x_2\end{pmatrix}\stackrel?=
a\begin{pmatrix}x_1\\x_2\end{pmatrix}+
b\begin{pmatrix}x_1\\x_2\end{pmatrix}
\, .
$$ 
Once again this is a simple LHS=RHS proof using properties of the real numbers. Starting on the left we have
$$
(a+b)
\begin{pmatrix}x_1\\x_2\end{pmatrix}
=
\begin{pmatrix}(a+b)x_1\\(a+b)x_2\end{pmatrix}
=
\begin{pmatrix}ax_1+b x_1\\ax_2+bx_2\end{pmatrix}
\qquad\qquad$$ $$\qquad\qquad=
\begin{pmatrix}ax_1\\ax_2\end{pmatrix}+
\begin{pmatrix}b x_1\\bx_2\end{pmatrix}
=
a\begin{pmatrix}x_1\\x_2\end{pmatrix}+
b\begin{pmatrix} x_1\\x_2\end{pmatrix}\, ,
$$
as required.
\item[($\cdot$iii)] Additive distributivity:
This time we need to check the equation
The equation we need to check is
$$
a\left(
\begin{pmatrix}x_1\\x_2\end{pmatrix}
+
\begin{pmatrix}y_1\\y_2\end{pmatrix}\right)\stackrel?=
a\begin{pmatrix}x_1\\x_2\end{pmatrix}+
a\begin{pmatrix}y_1\\y_2\end{pmatrix}
\, ,
$$ 
{\it i.e.}, one scalar but two different vectors.
The method is by now becoming familiar
$$
a\left(
\begin{pmatrix}x_1\\x_2\end{pmatrix}
+
\begin{pmatrix}y_1\\y_2\end{pmatrix}\right)=
a\left(
\begin{pmatrix}x_1+y_1\\x_2+y_2\end{pmatrix}
\right)
=
\begin{pmatrix}a(x_1+y_1)\\a(x_2+y_2)\end{pmatrix}
\qquad$$ $$\qquad\qquad=
\begin{pmatrix}ax_1+ay_1\\ax_2+ay_2\end{pmatrix}
=
\begin{pmatrix}ax_1\\ax_2\end{pmatrix}+
\begin{pmatrix}ay_1\\ay_2\end{pmatrix}
=
a\begin{pmatrix}x_1\\x_2\end{pmatrix}+
a\begin{pmatrix}y_1\\y_2\end{pmatrix}
\, ,
$$ 
again as required.
\item[($\cdot$iv)] Multiplicative associativity. 
Just as for addition, this is the requirement that the
order of bracketing does not matter.
We need to establish whether
$$
(a.b)\cdot\begin{pmatrix}x_1\\x_2\end{pmatrix}
\stackrel?=
a\cdot\left(b\cdot \begin{pmatrix}x_1\\x_2\end{pmatrix}\right)\, .
$$
This clearly holds for real numbers $a.(b.x)=(a.b).x$. The computation is
$$
(a.b)\cdot\begin{pmatrix}x_1\\x_2\end{pmatrix}
=
\begin{pmatrix}(a.b).x_1\\(a.b).x_2\end{pmatrix}
=
\begin{pmatrix}a.(b.x_1)\\a.(b.x_2)\end{pmatrix}
=
a.\begin{pmatrix}(b.x_1)\\(b.x_2)\end{pmatrix}
=
a\cdot\left(b\cdot \begin{pmatrix}x_1\\x_2\end{pmatrix}\right)\ ,
$$
which is what we want.
\item[($\cdot$v)] Unity: We need to find a special scalar
acts the way we would expect ``1'' to behave. {\it I.e.} $$
\mbox{``1''}\cdot\begin{pmatrix}x_1\\x_2\end{pmatrix}=\begin{pmatrix}x_1\\x_2\end{pmatrix}\, .
$$
There is an obvious choice for this special scalar---just the real number $1$ itself. Indeed, to be pedantic lets calculate
$$
1\cdot\begin{pmatrix}x_1\\x_2\end{pmatrix}=\begin{pmatrix}1.x_1\\1.x_2\end{pmatrix}=\begin{pmatrix}x_1\\x_2\end{pmatrix}\, .
$$
\end{enumerate}
Now we are done---we have really proven the ${\mathbb R}^2$ is a vector space so lets write a little square $\square$ to celebrate.


%%%%don't forget to close the bracket so the stuff after your file doesn't look like a movie!
}

%\newpage
