
\subsection{ \propDetTitle: The Adjoint Matrix}

%%%Insert this to get the typewriter font so it looks like a real movie script
{\ttfamily
\fontdimen2\font=0.4em
\fontdimen3\font=0.2em
\fontdimen4\font=0.1em
\fontdimen7\font=0.1em
\hyphenchar\font=`\-





%%%%put a hypertarget around the opening bit of text
\hypertarget{video_properties_of_determinant_adjoint}{In this} video we show how the adjoint 
matrix works in detail for the 3x3 case. Recall, that for a $2\times 2$ matrix
$$
M=\begin{pmatrix}a&b\\c&d\end{pmatrix}\, ,
$$
the matrix
$$
N=\begin{pmatrix}d&-b\\ -c & a\end{pmatrix}
$$
had the marvelous property
$$
MN=(\det M)\, I
$$
(you can easily check this for yourself). We call $$N:={\rm adj} M\, ,$$ the 
adjoint matrix of $M$. When the determinant $\det M\neq 0$, we can use it to immediately compute the inverse
$$
M^{-1}=\frac{1}{\det M}\, {\rm adj}M\, .
$$
Lets now think about a $3\times 3$ matrix 
$$
M=\begin{pmatrix}
a &b&c\\d&e&f\\g&h&i\end{pmatrix}\, .
$$
The first thing to remember is that we can compute the determinant by expanding in a row and computing determinants of minors, so
$$
\det M = a \det\begin{pmatrix}a&b\\c&d\end{pmatrix}
-b\det\begin{pmatrix}d&g\\f&i\end{pmatrix}
+c\det\begin{pmatrix}e&f\\h&i\end{pmatrix}\, .
$$
We can think of this as the product of a row and column vector
$$
\det M = \Big( a \ b \ c \Big)
\begin{pmatrix} \det\begin{pmatrix}a&b\\c&d\end{pmatrix}\\[2mm]
-\det\begin{pmatrix}d&g\\f&i\end{pmatrix}\ \ \\[2mm]
\det\begin{pmatrix}e&f\\h&i\end{pmatrix}\end{pmatrix}\, .
$$
Now, we try a little experiment. Lets multiply the same column vector by the other two rows of $M$
$$
 \Big( d \ e \ f \Big)
\begin{pmatrix} \det\begin{pmatrix}a&b\\c&d\end{pmatrix}\\[2mm]
-\det\begin{pmatrix}d&g\\f&i\end{pmatrix}\ \ \\[2mm]
\det\begin{pmatrix}e&f\\h&i\end{pmatrix}\end{pmatrix} = 0 =
 \Big( g \ h \ i \Big)
\begin{pmatrix} \det\begin{pmatrix}a&b\\c&d\end{pmatrix}\\[2mm]
-\det\begin{pmatrix}d&g\\f&i\end{pmatrix}\ \ \\[2mm]
\det\begin{pmatrix}e&f\\h&i\end{pmatrix}\end{pmatrix}
$$
The answer, ZERO, for both these computations, has been written in already because it is obvious. This is because these two computations are really computing
$$
\det\begin{pmatrix}
d &e&f\\d&e&f\\g&h&i\end{pmatrix}
\quad\mbox{and} \quad \det\begin{pmatrix}
g &h&i\\d&e&f\\g&h&i\end{pmatrix}\, .
$$
These vanish because the determinant of an matrix with a pair of equal rows is zero.
Thus we have found a nice result
$$
M \, \begin{pmatrix} \det\begin{pmatrix}a&b\\c&d\end{pmatrix}\\[2mm]
-\det\begin{pmatrix}d&g\\f&i\end{pmatrix}\ \ \\[2mm]
\det\begin{pmatrix}e&f\\h&i\end{pmatrix}\end{pmatrix}
=\det M \begin{pmatrix}1\\0\\0\end{pmatrix}\, .
$$
Notice the answer is the number $\det M$ times the first column of the identity matrix.
In fact, the column vector above is exactly the first column of the adjoint matrix ${\rm adj} M$.
The rule how to get the rest of the adjoint matrix is not hard. You first compute the cofactor matrix obtained by replacing the entries of $M$ with the signed determinants of the corresponding 
minors got by deleting the row and column of the particular entry. For the $3\times 3$ case this is
$$
{\rm cofactor} M = 
\begin{pmatrix} \det\begin{pmatrix}e&f\\h&i\end{pmatrix}
&-\det\begin{pmatrix}d&f\\g&i\end{pmatrix}
&\det\begin{pmatrix}d&e\\g&h\end{pmatrix}
\\[2mm]
-\det\begin{pmatrix}b&c\\h&i\end{pmatrix}
&\det\begin{pmatrix}a&c\\g&i\end{pmatrix}
&-\det\begin{pmatrix}a&b\\g&h\end{pmatrix}\\[2mm]
\det\begin{pmatrix}b&c\\e&f\end{pmatrix}
&-\det\begin{pmatrix}a&c\\d&f\end{pmatrix}
&\det\begin{pmatrix}a&b\\c&d\end{pmatrix}
\end{pmatrix}\, .
$$
Then the adjoint is just the transpose
$$
{\rm adj}M=\big({\rm cofactor} M\big)^T\, .
$$
Computing all this is a little tedious, but always works, even for any $n\times n$ matrix.
Moreover, when $\det M \neq 0$, we thus obtain the inverse
$
M^{-1}=\frac{1}{\det M}\, {\rm adj}M
$.


%%%%don't forget to close the bracket so the stuff after your file doesn't look like a movie!
}

\newpage
